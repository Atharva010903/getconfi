{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":97919,"databundleVersionId":11872932,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-26T10:11:34.025404Z","iopub.execute_input":"2025-04-26T10:11:34.025748Z","iopub.status.idle":"2025-04-26T10:11:35.603041Z","shell.execute_reply.started":"2025-04-26T10:11:34.025723Z","shell.execute_reply":"2025-04-26T10:11:35.602147Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/shl-intern-hiring-assessment/Dataset/sample_submission.csv\n/kaggle/input/shl-intern-hiring-assessment/Dataset/train.csv\n/kaggle/input/shl-intern-hiring-assessment/Dataset/test.csv\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_885.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1142.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1006.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_817.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_765.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_508.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_257.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_330.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_72.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_328.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_858.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_464.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_505.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_853.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1001.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_855.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_995.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_472.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1028.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_550.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_841.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_256.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_641.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1131.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_234.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_284.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_188.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1220.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_67.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_818.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_967.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_709.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_872.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1165.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_415.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_714.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1231.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_430.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_27.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1207.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_922.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_976.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1180.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_327.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1212.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1092.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1270.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1163.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1041.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_940.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_563.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_661.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_220.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_57.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1136.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1179.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_41.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_590.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1294.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_161.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1069.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_261.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1246.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_89.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_952.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_846.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_909.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1088.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_989.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_865.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_278.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1300.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_298.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_178.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_674.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1104.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_966.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1134.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1079.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1329.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_542.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_954.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_171.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_530.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_822.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_14.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_689.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_309.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1046.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_502.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_568.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_80.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_13.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_668.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1170.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_47.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_218.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1316.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_904.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_268.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_130.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_273.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_962.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1226.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_452.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_585.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1286.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_692.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_357.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_335.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_681.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1186.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_766.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_686.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1099.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_339.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_534.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_531.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1326.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_397.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1218.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_453.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_670.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1090.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1102.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_24.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_978.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_746.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1158.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_682.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_324.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_358.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_377.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_744.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_249.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_956.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_854.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_981.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_245.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_903.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_749.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_929.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_529.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_828.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_236.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_200.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_935.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1200.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_353.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1055.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1255.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_501.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_947.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1217.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_804.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_168.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_701.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_117.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_780.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1059.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_390.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_599.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_153.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_988.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_241.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_481.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_652.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_483.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_787.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1291.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1258.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1039.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_902.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_373.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1138.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1025.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_647.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1225.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1011.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_108.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_34.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_938.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_376.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_769.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_554.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_407.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_99.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_449.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_548.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_664.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_33.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_248.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_774.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_827.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_748.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_301.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_128.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_637.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_267.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_915.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1166.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_450.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_612.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1187.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_698.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1176.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_77.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1215.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_66.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_894.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_54.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1232.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_694.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_237.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1032.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_688.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_752.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_596.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_638.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_886.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_711.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_741.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_936.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_538.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1271.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_859.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_845.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_821.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_164.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1266.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1005.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1036.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_994.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_760.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_315.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1284.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1152.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_843.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_25.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_950.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1199.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_753.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1322.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1224.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_7.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1100.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1157.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_406.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_321.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_20.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_59.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_802.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_518.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1310.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_12.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_591.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_348.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1082.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_537.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_444.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_959.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_404.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_254.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_338.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_990.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_233.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_539.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_276.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1323.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_157.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_778.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_354.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_29.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_676.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_37.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_454.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_811.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1183.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_946.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_600.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1277.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_901.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_199.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1336.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1297.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_308.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_251.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_232.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1054.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_631.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_495.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_265.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1098.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_662.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_558.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_900.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_470.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_673.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_964.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_633.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_418.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_274.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_280.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_486.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1337.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_231.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_567.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_374.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1194.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_944.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_856.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1084.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_230.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1306.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_120.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_295.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_297.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_899.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_516.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_56.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1103.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_346.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1007.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_446.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_189.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1236.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_277.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_957.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_491.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1012.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_190.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_759.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_642.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_347.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_824.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_851.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_457.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1253.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1171.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_773.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_76.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_905.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1015.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_205.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_361.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1035.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1159.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_497.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_928.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_102.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_399.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_296.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_860.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_942.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_881.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_499.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1116.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_393.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_275.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_779.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1278.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_370.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_410.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1197.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_565.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_807.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1241.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_4.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_356.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_162.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_118.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1202.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_974.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_366.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_743.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_210.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_19.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1228.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_998.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1018.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_614.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_396.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1239.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_583.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1114.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_771.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1049.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_829.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1058.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1182.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1094.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_719.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1205.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_930.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_801.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1091.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_217.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_84.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_575.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_475.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1045.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_258.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_23.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_593.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_592.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_423.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1237.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_916.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_159.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_522.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_545.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_387.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_266.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_372.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_784.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1133.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_93.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_331.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_849.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_934.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_215.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_826.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_659.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_364.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_654.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1083.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_174.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_816.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_987.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_5.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_551.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1120.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1128.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1066.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1119.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1221.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_628.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_622.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_763.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_355.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_553.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_85.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_574.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_182.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_756.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_800.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_38.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_469.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_965.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_148.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_127.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_677.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_434.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_691.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1075.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1030.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_239.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_252.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_871.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_326.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_288.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_98.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1105.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_286.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_263.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_209.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_656.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_302.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_984.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_52.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_16.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_844.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_460.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1111.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_594.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_679.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1076.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_764.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_332.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1151.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1335.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1173.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_78.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_388.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_700.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_224.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_939.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1282.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1002.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_375.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_383.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_996.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_921.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_515.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_30.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_745.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_216.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1192.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1219.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_949.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_459.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_362.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_908.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_482.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_158.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1042.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_219.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1309.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_533.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_154.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_958.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1249.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_805.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_630.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_730.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_611.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_92.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_69.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_385.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_221.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_131.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_336.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_880.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_707.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1238.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1330.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_742.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_292.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_754.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_716.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1276.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_985.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1161.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_840.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1029.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_68.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_671.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_432.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1078.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_155.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_378.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_264.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_360.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_349.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1240.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_212.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_183.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_474.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_419.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_316.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1332.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_242.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_667.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1254.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1072.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1132.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_825.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_586.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_226.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_426.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1019.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_39.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_890.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_197.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_213.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1168.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1290.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1339.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_136.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_893.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1314.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_687.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_312.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_147.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_783.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_144.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_710.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_706.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_573.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1214.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_139.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_503.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_134.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_18.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_116.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_789.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1087.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_523.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_420.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1156.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_135.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1223.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_325.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_556.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_669.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_755.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_973.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_678.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_655.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1265.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_250.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1299.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1174.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_512.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_150.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_392.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_73.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_43.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_712.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_437.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_613.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_493.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_704.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_431.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_3.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_832.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_428.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_658.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_58.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_471.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1117.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_713.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_768.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_640.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1023.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_566.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1135.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_36.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_201.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_74.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1320.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1127.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_993.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_480.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_560.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_877.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_852.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1096.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_514.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_696.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1234.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_151.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_557.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_473.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_651.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_724.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_259.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_795.wav\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#importing all basic libraries required in code\nimport numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport librosa\nimport soundfile as sf\nfrom tqdm.notebook import tqdm\nimport re\nimport torch\nfrom scipy.stats import pearsonr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T10:11:35.604238Z","iopub.execute_input":"2025-04-26T10:11:35.604632Z","iopub.status.idle":"2025-04-26T10:11:37.678849Z","shell.execute_reply.started":"2025-04-26T10:11:35.604608Z","shell.execute_reply":"2025-04-26T10:11:37.678208Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install librosa pydub openai-whisper transformers sentencepiece torch pandas scikit-learn language-tool-python spacy nltk happytransformer\n!python -m spacy download en_core_web_sm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T10:11:37.679691Z","iopub.execute_input":"2025-04-26T10:11:37.680054Z","iopub.status.idle":"2025-04-26T10:11:50.153039Z","shell.execute_reply.started":"2025-04-26T10:11:37.680034Z","shell.execute_reply":"2025-04-26T10:11:50.152252Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\nRequirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (20240930)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: language-tool-python in /usr/local/lib/python3.11/dist-packages (2.9.3)\nRequirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: happytransformer in /usr/local/lib/python3.11/dist-packages (3.0.0)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\nRequirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\nRequirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.2)\nRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\nRequirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\nRequirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\nRequirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\nRequirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.1)\nRequirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\nRequirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (7.0.0)\nRequirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from language-tool-python) (0.10.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\nRequirement already satisfied: datasets<3.0.0,>=2.13.1 in /usr/local/lib/python3.11/dist-packages (from happytransformer) (2.21.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from happytransformer) (3.20.3)\nRequirement already satisfied: accelerate<1.0.0,>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from happytransformer) (0.34.2)\nRequirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from happytransformer) (0.19.6)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (0.3.8)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (0.70.16)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (3.11.16)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (3.1.44)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (2.21.0)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (1.3.4)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (1.19.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->happytransformer) (4.0.12)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2024.2.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->happytransformer) (5.0.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\nCollecting en-core-web-sm==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.33.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.13.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n\u001b[38;5;2m Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[38;5;3m Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import transformers\nprint(transformers.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T10:11:50.155691Z","iopub.execute_input":"2025-04-26T10:11:50.155993Z","iopub.status.idle":"2025-04-26T10:11:50.539129Z","shell.execute_reply.started":"2025-04-26T10:11:50.155968Z","shell.execute_reply":"2025-04-26T10:11:50.538242Z"}},"outputs":[{"name":"stdout","text":"4.51.1\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"## Create processed audio directory and load training CSV with renamed columns\n\nAUDIO_DIR = '/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train'\nCSV_PATH = '/kaggle/input/shl-intern-hiring-assessment/Dataset/train.csv'\nPROCESSED_DIR = '/kaggle/working/processed_audio'\nos.makedirs(PROCESSED_DIR, exist_ok=True)\n\n# Load CSV and rename columns\ntrain_df = pd.read_csv(CSV_PATH)\ntrain_df.columns = ['filename', 'label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T10:11:50.539977Z","iopub.execute_input":"2025-04-26T10:11:50.540997Z","iopub.status.idle":"2025-04-26T10:11:50.550471Z","shell.execute_reply.started":"2025-04-26T10:11:50.540973Z","shell.execute_reply":"2025-04-26T10:11:50.549843Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"## Detect whether an audio file contains speech by analyzing silence, speech ratio, and zero-crossing rate variation\n\ndef detect_speech_content(audio_path):\n    \"\"\"Determine if audio contains speech or just instrumental/noise\"\"\"\n    y, sr = librosa.load(audio_path, sr=16000)\n    \n    # Multiple detection methods\n    non_silence = librosa.effects.split(y, top_db=25)\n    speech_ratio = sum(end-start for start, end in non_silence) / len(y) if len(y) > 0 else 0\n    \n    # Zero-crossing rate variance (speech has more variation than music)\n    zcr = librosa.feature.zero_crossing_rate(y)[0]\n    zcr_std = np.std(zcr)\n    \n    # Combined check\n    has_speech = speech_ratio > 0.1 and zcr_std > 0.05\n    return has_speech","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T10:11:50.551272Z","iopub.execute_input":"2025-04-26T10:11:50.551482Z","iopub.status.idle":"2025-04-26T10:11:50.558421Z","shell.execute_reply.started":"2025-04-26T10:11:50.551465Z","shell.execute_reply":"2025-04-26T10:11:50.557772Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Function: Preprocess audio by resampling, normalizing volume, and trimming silence\ndef preprocess_audio(file_path, save_path, sr=16000):\n    \"\"\"Enhanced preprocessing with speech detection\"\"\"\n    y, orig_sr = librosa.load(file_path, sr=None)\n    if orig_sr != sr:\n        y = librosa.resample(y, orig_sr, sr)\n    \n    # Normalize volume\n    y = y / max(abs(y)) if max(abs(y)) > 0 else y\n    \n    # Trim silence\n    y, _ = librosa.effects.trim(y, top_db=25)\n    sf.write(save_path, y, sr)\n# Function: Detect whether an audio contains speech using silence trimming and ZCR variation\n# Process each audio file\n\n# Important: Preprocessing each audio file and detecting speech before transcription\nspeech_flags = []\nfor filename in tqdm(train_df['filename']):\n    in_path = os.path.join(AUDIO_DIR, filename)\n    out_path = os.path.join(PROCESSED_DIR, filename)\n    \n    # Original preprocessing\n    preprocess_audio(in_path, out_path)\n    \n    # Add speech detection\n    has_speech = detect_speech_content(out_path)\n    speech_flags.append(has_speech)\n\n# Add speech flag to dataframe\ntrain_df['has_speech'] = speech_flags\n\n# Report number of non-speech files (useful for understanding audio content distribution)\nnon_speech_count = sum(1 for flag in speech_flags if not flag)\nprint(f\" Detected {non_speech_count}/{len(speech_flags)} files as non-speech/instrumental\")\n\n# Check sample rate and duration of a random file\nfiles = os.listdir(PROCESSED_DIR)\nprint(f\" Found {len(files)} preprocessed audio files.\\nExample files:\\n\", files[:5])\n\nsample_file = os.path.join(PROCESSED_DIR, files[0])\ny, sr = librosa.load(sample_file, sr=None)\n\nduration = librosa.get_duration(y=y, sr=sr)\nprint(f\" Sample file: {files[0]}\")\nprint(f\" Duration: {duration:.2f} seconds\")\nprint(f\" Sample rate: {sr} Hz\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T10:11:50.559181Z","iopub.execute_input":"2025-04-26T10:11:50.559410Z","iopub.status.idle":"2025-04-26T10:18:44.220306Z","shell.execute_reply.started":"2025-04-26T10:11:50.559370Z","shell.execute_reply":"2025-04-26T10:18:44.219645Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/444 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8f3cd8b45a24ef589689753ac1e8055"}},"metadata":{}},{"name":"stdout","text":" Detected 13/444 files as non-speech/instrumental\n Found 444 preprocessed audio files.\nExample files:\n ['audio_807.wav', 'audio_475.wav', 'audio_655.wav', 'audio_1199.wav', 'audio_600.wav']\n Sample file: audio_807.wav\n Duration: 19.71 seconds\n Sample rate: 16000 Hz\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Load Whisper ASR model for transcription\nimport whisper\n\n# Load Whisper ASR model\nwhisper_model= whisper.load_model(\"base\")  # Options: tiny, base, small, medium, large\n\n#  Important: Transcribe only speech-containing files to save compute and avoid noise\ntranscripts = []\n\nfor idx, row in tqdm(train_df.iterrows()):\n    fname = row['filename']\n    audio_path = os.path.join(PROCESSED_DIR, fname)\n    \n    if row['has_speech']:\n        # Normal transcription for speech files\n        result = whisper_model.transcribe(audio_path, language='en')\n        transcript = result['text']\n    else:\n        # Skip transcription for non-speech files\n        transcript = \"\"\n    \n    transcripts.append(transcript)\n\n# Add transcripts to dataframe\ntrain_df['transcript'] = transcripts\n\n# Save updated CSV\ntrain_df.to_csv('/kaggle/working/train_with_transcripts.csv', index=False)\nprint(\" Transcriptions saved to: /kaggle/working/train_with_transcripts.csv\")\n\n# Sample transcript review\ndf = pd.read_csv('/kaggle/working/train_with_transcripts.csv')\nprint(\" Columns:\", df.columns.tolist())\nprint(\" Total records:\", len(df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T10:18:44.221168Z","iopub.execute_input":"2025-04-26T10:18:44.221653Z","iopub.status.idle":"2025-04-26T10:43:08.644739Z","shell.execute_reply.started":"2025-04-26T10:18:44.221625Z","shell.execute_reply":"2025-04-26T10:43:08.644036Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(fp, map_location=device)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee5c5c53baad45bcb123451adf5e1d8a"}},"metadata":{}},{"name":"stdout","text":" Transcriptions saved to: /kaggle/working/train_with_transcripts.csv\n Columns: ['filename', 'label', 'has_speech', 'transcript']\n Total records: 444\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\" Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T10:43:08.645640Z","iopub.execute_input":"2025-04-26T10:43:08.645955Z","iopub.status.idle":"2025-04-26T10:43:08.650561Z","shell.execute_reply.started":"2025-04-26T10:43:08.645927Z","shell.execute_reply":"2025-04-26T10:43:08.649910Z"}},"outputs":[{"name":"stdout","text":" Using device: cuda\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"FILLERS = ['uh', 'um', 'erm', 'you know', 'like', 'i mean', 'hmm', 'ah', 'uhh', 'huh']\n\ndef clean_transcript(text):\n    text = text.lower()  # Standard casing\n    text = re.sub(r'\\b(?:' + '|'.join(FILLERS) + r')\\b', '', text)  # Remove fillers\n    text = re.sub(r'\\s+', ' ', text)  # Collapse multiple spaces\n    text = re.sub(r'\\s([?.!,\"])', r'\\1', text)  # Remove space before punctuation\n    text = text.strip()\n    return text\n\n# Clean all transcripts\ndf['cleaned_transcript'] = df['transcript'].astype(str).apply(clean_transcript)\n\n# Save new version\ndf.to_csv('/kaggle/working/train_cleaned.csv', index=False)\nprint(\" Cleaned transcripts saved to: /kaggle/working/train_cleaned.csv\")\nprint(df[['transcript', 'cleaned_transcript']].sample(3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T10:43:08.653471Z","iopub.execute_input":"2025-04-26T10:43:08.653697Z","iopub.status.idle":"2025-04-26T10:43:08.723573Z","shell.execute_reply.started":"2025-04-26T10:43:08.653681Z","shell.execute_reply":"2025-04-26T10:43:08.722917Z"}},"outputs":[{"name":"stdout","text":" Cleaned transcripts saved to: /kaggle/working/train_cleaned.csv\n                                            transcript  \\\n6     I would like to go the Sachi for the Sachi's ...   \n43    My tone is my entire world. I was right there...   \n354   Favorite place that I like to visit would def...   \n\n                                    cleaned_transcript  \n6    i would to go the sachi for the sachi's tup. h...  \n43   my tone is my entire world. i was right there....  \n354  favorite place that i to visit would definitel...  \n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"!pip install language-tool-python==2.7.1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T10:43:08.724226Z","iopub.execute_input":"2025-04-26T10:43:08.724415Z","iopub.status.idle":"2025-04-26T10:43:12.205272Z","shell.execute_reply.started":"2025-04-26T10:43:08.724401Z","shell.execute_reply":"2025-04-26T10:43:12.204237Z"}},"outputs":[{"name":"stdout","text":"Collecting language-tool-python==2.7.1\n  Downloading language_tool_python-2.7.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language-tool-python==2.7.1) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from language-tool-python==2.7.1) (4.67.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python==2.7.1) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python==2.7.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python==2.7.1) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python==2.7.1) (2025.1.31)\nDownloading language_tool_python-2.7.1-py3-none-any.whl (34 kB)\nInstalling collected packages: language-tool-python\n  Attempting uninstall: language-tool-python\n    Found existing installation: language_tool_python 2.9.3\n    Uninstalling language_tool_python-2.9.3:\n      Successfully uninstalled language_tool_python-2.9.3\nSuccessfully installed language-tool-python-2.7.1\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!apt-get update\n!apt-get install -y openjdk-11-jdk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T10:43:12.206523Z","iopub.execute_input":"2025-04-26T10:43:12.206790Z","iopub.status.idle":"2025-04-26T10:43:30.410563Z","shell.execute_reply.started":"2025-04-26T10:43:12.206762Z","shell.execute_reply":"2025-04-26T10:43:30.409784Z"}},"outputs":[{"name":"stdout","text":"Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]                \nGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,607 kB]\nGet:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [75.2 kB]                 \nHit:5 http://archive.ubuntu.com/ubuntu jammy InRelease                                              \nGet:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]                           \nGet:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]                             \nGet:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]                                \nGet:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]              \nGet:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,863 kB]                      \nGet:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]                          \nGet:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,118 kB]        \nGet:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]       \nGet:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,543 kB]            \nHit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease                        \nGet:16 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [34.3 kB]   \nGet:17 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [47.4 kB]\nGet:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,272 kB]          \nGet:19 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,844 kB]              \nGet:20 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,244 kB]          \nGet:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,154 kB]                \nGet:22 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]           \nGet:23 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,701 kB]                 \nFetched 31.0 MB in 4s (7,235 kB/s)                           \nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following additional packages will be installed:\n  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java libatk-wrapper-java-jni libxtst6\n  libxxf86dga1 openjdk-11-jre x11-utils\nSuggested packages:\n  openjdk-11-demo openjdk-11-source visualvm mesa-utils\nThe following NEW packages will be installed:\n  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java libatk-wrapper-java-jni libxtst6\n  libxxf86dga1 openjdk-11-jdk openjdk-11-jre x11-utils\n0 upgraded, 9 newly installed, 0 to remove and 151 not upgraded.\nNeed to get 4,970 kB of archives.\nAfter this operation, 13.8 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\nGet:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\nGet:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\nGet:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\nGet:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\nGet:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\nGet:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre amd64 11.0.26+4-1ubuntu1~22.04 [214 kB]\nGet:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jdk amd64 11.0.26+4-1ubuntu1~22.04 [1,341 kB]\nFetched 4,970 kB in 4s (1,418 kB/s)     \nSelecting previously unselected package fonts-dejavu-core.\n(Reading database ... 128691 files and directories currently installed.)\nPreparing to unpack .../0-fonts-dejavu-core_2.37-2build1_all.deb ...\nUnpacking fonts-dejavu-core (2.37-2build1) ...\nSelecting previously unselected package fonts-dejavu-extra.\nPreparing to unpack .../1-fonts-dejavu-extra_2.37-2build1_all.deb ...\nUnpacking fonts-dejavu-extra (2.37-2build1) ...\nSelecting previously unselected package libxtst6:amd64.\nPreparing to unpack .../2-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\nUnpacking libxtst6:amd64 (2:1.2.3-1build4) ...\nSelecting previously unselected package libxxf86dga1:amd64.\nPreparing to unpack .../3-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\nUnpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\nSelecting previously unselected package x11-utils.\nPreparing to unpack .../4-x11-utils_7.7+5build2_amd64.deb ...\nUnpacking x11-utils (7.7+5build2) ...\nSelecting previously unselected package libatk-wrapper-java.\nPreparing to unpack .../5-libatk-wrapper-java_0.38.0-5build1_all.deb ...\nUnpacking libatk-wrapper-java (0.38.0-5build1) ...\nSelecting previously unselected package libatk-wrapper-java-jni:amd64.\nPreparing to unpack .../6-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\nUnpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\nSelecting previously unselected package openjdk-11-jre:amd64.\nPreparing to unpack .../7-openjdk-11-jre_11.0.26+4-1ubuntu1~22.04_amd64.deb ...\nUnpacking openjdk-11-jre:amd64 (11.0.26+4-1ubuntu1~22.04) ...\nSelecting previously unselected package openjdk-11-jdk:amd64.\nPreparing to unpack .../8-openjdk-11-jdk_11.0.26+4-1ubuntu1~22.04_amd64.deb ...\nUnpacking openjdk-11-jdk:amd64 (11.0.26+4-1ubuntu1~22.04) ...\nSetting up libxtst6:amd64 (2:1.2.3-1build4) ...\nSetting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\nSetting up openjdk-11-jre:amd64 (11.0.26+4-1ubuntu1~22.04) ...\nSetting up fonts-dejavu-core (2.37-2build1) ...\nSetting up fonts-dejavu-extra (2.37-2build1) ...\nSetting up x11-utils (7.7+5build2) ...\nSetting up openjdk-11-jdk:amd64 (11.0.26+4-1ubuntu1~22.04) ...\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\nSetting up libatk-wrapper-java (0.38.0-5build1) ...\nSetting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\nProcessing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\nProcessing triggers for hicolor-icon-theme (0.17-2) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.8) ...\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\nProcessing triggers for man-db (2.10.2-1) ...\nProcessing triggers for mailcap (3.70+nmu1ubuntu1) ...\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import spacy\nfrom happytransformer import HappyTextToText, TTSettings\nimport re\nfrom tqdm import tqdm\nimport pandas as pd\n\n# Load NLP model\ntry:\n    nlp = spacy.load(\"en_core_web_sm\")\nexcept:\n    # If model isn't installed, download it\n    import spacy.cli\n    spacy.cli.download(\"en_core_web_sm\")\n    nlp = spacy.load(\"en_core_web_sm\")\n\n# Load text correction model\nhappy_tt = HappyTextToText(\"T5\", \"vennify/t5-base-grammar-correction\")\nargs = TTSettings(\n    num_beams=5,\n    do_sample=False,\n    temperature=1.0,\n    top_k=50,\n    top_p=1.0\n)\ndef simple_grammar_check(text):\n    \"\"\"Simple rule-based grammar checker to replace LanguageTool\"\"\"\n    errors = 0\n    \n    # Check for common grammar issues\n    # Double spaces\n    errors += len(re.findall(r\"  +\", text))\n    \n    # Missing period at end of sentence\n    errors += len(re.findall(r\"[a-zA-Z]$\", text))\n    \n    # Missing capitalization after period\n    errors += len(re.findall(r\"\\. [a-z]\", text))\n    \n    # Double punctuation\n    errors += len(re.findall(r\"[,.!?]{2,}\", text))\n    \n    # Common spelling mistakes (very basic)\n    common_mistakes = [\"teh\", \"alot\", \"definately\", \"occured\", \"recieve\", \n                       \"seperate\", \"wierd\", \"accomodate\", \"goverment\", \"wich\"]\n    \n    for mistake in common_mistakes:\n        errors += len(re.findall(r\"\\b\" + mistake + r\"\\b\", text.lower()))\n    \n    return errors\n\ndef extract_enhanced_features(text, has_speech=True):\n    \"\"\"Extract comprehensive linguistic features with special handling for non-speech\"\"\"\n    features = {}\n    \n    # Special case for non-speech or empty text\n    if not has_speech or not text.strip():\n        features['is_empty'] = 1\n        features['grammar_errors'] = 0\n        features['avg_sentence_length'] = 0\n        features['pos_diversity'] = 0\n        features['word_count'] = 0\n        features['grammar_errors_per_word'] = 0\n        features['gec_edits'] = 0\n        features['gec_edit_rate'] = 0\n        features['lexical_diversity'] = 0\n        features['avg_word_length'] = 0\n        features['readability_score'] = 0\n        return features\n    \n    # Text is not empty, extract normal features\n    doc = nlp(text)\n    \n    # Regular features\n    features['is_empty'] = 0\n    features['grammar_errors'] = simple_grammar_check(text)  # Using our custom checker\n    \n    # Calculate sentence lengths\n    sentences = list(doc.sents)\n    if sentences:\n        sent_lengths = [len(sent) for sent in sentences]\n        features['avg_sentence_length'] = sum(sent_lengths) / len(sent_lengths)\n    else:\n        features['avg_sentence_length'] = 0\n    \n    pos_tags = [token.pos_ for token in doc if token.pos_ != 'SPACE']\n    features['pos_diversity'] = len(set(pos_tags)) if pos_tags else 0\n\n    # Word count and error rate\n    words = text.split()\n    features['word_count'] = len(words)\n    features['grammar_errors_per_word'] = features['grammar_errors'] / max(1, features['word_count'])\n    \n    # GEC features - grammar correction edits\n    if text.strip():\n        corrected = happy_tt.generate_text(\"grammar: \" + text).text\n        corrected_words = corrected.split()\n        \n        # Calculate edits\n        min_len = min(len(words), len(corrected_words))\n        edits = sum(1 for i in range(min_len) if words[i] != corrected_words[i])\n        edits += abs(len(words) - len(corrected_words))\n        \n        features['gec_edits'] = edits\n        features['gec_edit_rate'] = edits / max(1, len(words))\n    else:\n        features['gec_edits'] = 0\n        features['gec_edit_rate'] = 0\n    \n    # Enhanced features\n    # Lexical diversity (unique words / total words)\n    unique_words = len(set([token.text.lower() for token in doc if token.is_alpha]))\n    features['lexical_diversity'] = unique_words / max(1, features['word_count'])\n    \n    # Average word length\n    features['avg_word_length'] = sum(len(w) for w in words) / max(1, len(words))\n    \n    # Readability score (simplified Flesch)\n    features['readability_score'] = 206.835 - (1.015 * features['avg_sentence_length']) - (84.6 * features['avg_word_length'])\n    \n    return features\n\n# Process all rows in dataframe\nall_features = []\nfor idx, row in tqdm(df.iterrows()):\n    text = row['cleaned_transcript']\n    has_speech = row['has_speech']\n    features = extract_enhanced_features(text, has_speech)\n    all_features.append(features)\n\n# Convert to DataFrame and add to main DataFrame\nfeatures_df = pd.DataFrame(all_features)\nenhanced_df = pd.concat([df, features_df], axis=1)\n\n# Save enhanced features\nenhanced_df.to_csv('/kaggle/working/train_features_enhanced.csv', index=False)\nprint(\" Enhanced features saved to: /kaggle/working/train_features_enhanced.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T10:43:30.411686Z","iopub.execute_input":"2025-04-26T10:43:30.412040Z","iopub.status.idle":"2025-04-26T10:50:04.736653Z","shell.execute_reply.started":"2025-04-26T10:43:30.412005Z","shell.execute_reply":"2025-04-26T10:50:04.735819Z"}},"outputs":[{"name":"stderr","text":"2025-04-26 10:43:35.503593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745664215.684888     148 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745664215.737739     148 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b1604343a044bda9a8c189a49016515"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fa1184c4580484d805cbb5797677a0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b409c014907481d9701169fd02f5a3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9035b9a751874e9eae192fcf1e9637e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"476c1280e9d942bcb2c23161ad700dac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a11e15279d1a4855b477f578e52a57e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee83d11e5f924b8ea546222256407be5"}},"metadata":{}},{"name":"stderr","text":"\n0it [00:00, ?it/s]\u001b[ADevice set to use cuda:0\n\n1it [00:01,  1.40s/it]\u001b[A\n2it [00:02,  1.05it/s]\u001b[A\n3it [00:02,  1.12it/s]\u001b[A\n4it [00:03,  1.43it/s]\u001b[A\n5it [00:04,  1.33it/s]\u001b[A\n6it [00:04,  1.26it/s]\u001b[A\n7it [00:05,  1.23it/s]\u001b[A\n8it [00:06,  1.39it/s]\u001b[A\n9it [00:07,  1.22it/s]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (904 > 512). Running this sequence through the model will result in indexing errors\n\n10it [00:08,  1.07it/s]\u001b[AYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n\n11it [00:09,  1.11it/s]\u001b[A\n12it [00:10,  1.14it/s]\u001b[A\n13it [00:11,  1.17it/s]\u001b[A\n14it [00:11,  1.16it/s]\u001b[A\n15it [00:12,  1.16it/s]\u001b[A\n16it [00:13,  1.14it/s]\u001b[A\n17it [00:14,  1.16it/s]\u001b[A\n18it [00:15,  1.16it/s]\u001b[A\n19it [00:16,  1.15it/s]\u001b[A\n20it [00:17,  1.16it/s]\u001b[A\n21it [00:17,  1.18it/s]\u001b[A\n22it [00:18,  1.18it/s]\u001b[A\n25it [00:19,  1.90it/s]\u001b[A\n26it [00:20,  1.68it/s]\u001b[A\n27it [00:21,  1.55it/s]\u001b[A\n29it [00:22,  1.82it/s]\u001b[A\n30it [00:22,  1.59it/s]\u001b[A\n31it [00:23,  1.48it/s]\u001b[A\n32it [00:24,  1.39it/s]\u001b[A\n33it [00:25,  1.34it/s]\u001b[A\n34it [00:26,  1.30it/s]\u001b[A\n35it [00:27,  1.27it/s]\u001b[A\n36it [00:27,  1.24it/s]\u001b[A\n37it [00:28,  1.23it/s]\u001b[A\n40it [00:29,  1.94it/s]\u001b[A\n41it [00:30,  1.70it/s]\u001b[A\n42it [00:31,  1.55it/s]\u001b[A\n43it [00:32,  1.45it/s]\u001b[A\n44it [00:33,  1.36it/s]\u001b[A\n45it [00:33,  1.30it/s]\u001b[A\n46it [00:34,  1.27it/s]\u001b[A\n47it [00:35,  1.24it/s]\u001b[A\n48it [00:36,  1.22it/s]\u001b[A\n49it [00:37,  1.26it/s]\u001b[A\n50it [00:37,  1.24it/s]\u001b[A\n51it [00:38,  1.23it/s]\u001b[A\n52it [00:39,  1.22it/s]\u001b[A\n53it [00:40,  1.20it/s]\u001b[A\n54it [00:41,  1.20it/s]\u001b[A\n55it [00:42,  1.19it/s]\u001b[A\n56it [00:42,  1.33it/s]\u001b[A\n57it [00:43,  1.30it/s]\u001b[A\n58it [00:44,  1.27it/s]\u001b[A\n59it [00:45,  1.25it/s]\u001b[A\n60it [00:46,  1.24it/s]\u001b[A\n61it [00:46,  1.22it/s]\u001b[A\n62it [00:47,  1.18it/s]\u001b[A\n63it [00:48,  1.18it/s]\u001b[A\n64it [00:49,  1.19it/s]\u001b[A\n65it [00:50,  1.19it/s]\u001b[A\n66it [00:51,  1.27it/s]\u001b[A\n67it [00:51,  1.24it/s]\u001b[A\n68it [00:52,  1.21it/s]\u001b[A\n69it [00:53,  1.21it/s]\u001b[A\n70it [00:54,  1.20it/s]\u001b[A\n71it [00:55,  1.20it/s]\u001b[A\n72it [00:56,  1.19it/s]\u001b[A\n73it [00:56,  1.18it/s]\u001b[A\n74it [00:57,  1.19it/s]\u001b[A\n75it [00:58,  1.19it/s]\u001b[A\n76it [00:59,  1.18it/s]\u001b[A\n77it [01:00,  1.17it/s]\u001b[A\n78it [01:01,  1.19it/s]\u001b[A\n79it [01:01,  1.19it/s]\u001b[A\n80it [01:02,  1.18it/s]\u001b[A\n82it [01:03,  1.54it/s]\u001b[A\n83it [01:04,  1.44it/s]\u001b[A\n84it [01:05,  1.37it/s]\u001b[A\n85it [01:06,  1.32it/s]\u001b[A\n86it [01:07,  1.29it/s]\u001b[A\n87it [01:07,  1.27it/s]\u001b[A\n89it [01:08,  1.63it/s]\u001b[A\n90it [01:09,  1.52it/s]\u001b[A\n91it [01:10,  1.45it/s]\u001b[A\n92it [01:11,  1.39it/s]\u001b[A\n93it [01:11,  1.35it/s]\u001b[A\n94it [01:12,  1.31it/s]\u001b[A\n95it [01:13,  1.29it/s]\u001b[A\n96it [01:14,  1.27it/s]\u001b[A\n97it [01:15,  1.27it/s]\u001b[A\n98it [01:15,  1.26it/s]\u001b[A\n99it [01:16,  1.26it/s]\u001b[A\n100it [01:17,  1.36it/s]\u001b[A\n101it [01:18,  1.33it/s]\u001b[A\n102it [01:18,  1.28it/s]\u001b[A\n103it [01:19,  1.26it/s]\u001b[A\n104it [01:20,  1.25it/s]\u001b[A\n105it [01:21,  1.24it/s]\u001b[A\n106it [01:22,  1.24it/s]\u001b[A\n107it [01:23,  1.21it/s]\u001b[A\n108it [01:23,  1.20it/s]\u001b[A\n109it [01:24,  1.19it/s]\u001b[A\n110it [01:25,  1.19it/s]\u001b[A\n111it [01:26,  1.19it/s]\u001b[A\n112it [01:27,  1.19it/s]\u001b[A\n113it [01:28,  1.19it/s]\u001b[A\n114it [01:28,  1.20it/s]\u001b[A\n115it [01:29,  1.20it/s]\u001b[A\n116it [01:30,  1.19it/s]\u001b[A\n117it [01:31,  1.17it/s]\u001b[A\n118it [01:32,  1.15it/s]\u001b[A\n119it [01:33,  1.17it/s]\u001b[A\n120it [01:34,  1.18it/s]\u001b[A\n121it [01:34,  1.18it/s]\u001b[A\n122it [01:35,  1.18it/s]\u001b[A\n125it [01:36,  1.87it/s]\u001b[A\n126it [01:37,  1.66it/s]\u001b[A\n127it [01:38,  1.50it/s]\u001b[A\n128it [01:39,  1.40it/s]\u001b[A\n129it [01:40,  1.35it/s]\u001b[A\n130it [01:40,  1.31it/s]\u001b[A\n131it [01:41,  1.27it/s]\u001b[A\n132it [01:42,  1.22it/s]\u001b[A\n133it [01:43,  1.21it/s]\u001b[A\n134it [01:44,  1.20it/s]\u001b[A\n135it [01:45,  1.20it/s]\u001b[A\n136it [01:45,  1.20it/s]\u001b[A\n137it [01:46,  1.18it/s]\u001b[A\n138it [01:47,  1.18it/s]\u001b[A\n139it [01:48,  1.18it/s]\u001b[A\n140it [01:49,  1.23it/s]\u001b[A\n141it [01:50,  1.22it/s]\u001b[A\n142it [01:50,  1.18it/s]\u001b[A\n143it [01:51,  1.17it/s]\u001b[A\n144it [01:52,  1.16it/s]\u001b[A\n145it [01:53,  1.15it/s]\u001b[A\n146it [01:54,  1.15it/s]\u001b[A\n147it [01:55,  1.14it/s]\u001b[A\n148it [01:56,  1.16it/s]\u001b[A\n149it [01:57,  1.17it/s]\u001b[A\n150it [01:57,  1.33it/s]\u001b[A\n151it [01:58,  1.26it/s]\u001b[A\n152it [01:59,  1.21it/s]\u001b[A\n153it [02:00,  1.21it/s]\u001b[A\n154it [02:01,  1.18it/s]\u001b[A\n156it [02:01,  1.52it/s]\u001b[A\n157it [02:02,  1.38it/s]\u001b[A\n158it [02:03,  1.31it/s]\u001b[A\n159it [02:04,  1.26it/s]\u001b[A\n160it [02:05,  1.23it/s]\u001b[A\n161it [02:06,  1.21it/s]\u001b[A\n162it [02:07,  1.19it/s]\u001b[A\n163it [02:08,  1.18it/s]\u001b[A\n164it [02:08,  1.18it/s]\u001b[A\n165it [02:09,  1.17it/s]\u001b[A\n166it [02:10,  1.17it/s]\u001b[A\n167it [02:11,  1.16it/s]\u001b[A\n168it [02:12,  1.14it/s]\u001b[A\n169it [02:13,  1.16it/s]\u001b[A\n170it [02:14,  1.15it/s]\u001b[A\n171it [02:15,  1.16it/s]\u001b[A\n172it [02:15,  1.17it/s]\u001b[A\n173it [02:16,  1.17it/s]\u001b[A\n174it [02:17,  1.17it/s]\u001b[A\n175it [02:18,  1.17it/s]\u001b[A\n176it [02:19,  1.18it/s]\u001b[A\n177it [02:20,  1.18it/s]\u001b[A\n178it [02:20,  1.18it/s]\u001b[A\n179it [02:21,  1.18it/s]\u001b[A\n180it [02:22,  1.13it/s]\u001b[A\n181it [02:23,  1.15it/s]\u001b[A\n182it [02:24,  1.16it/s]\u001b[A\n183it [02:25,  1.17it/s]\u001b[A\n184it [02:26,  1.17it/s]\u001b[A\n185it [02:26,  1.17it/s]\u001b[A\n186it [02:27,  1.17it/s]\u001b[A\n187it [02:28,  1.16it/s]\u001b[A\n188it [02:29,  1.16it/s]\u001b[A\n189it [02:30,  1.16it/s]\u001b[A\n190it [02:31,  1.15it/s]\u001b[A\n191it [02:32,  1.16it/s]\u001b[A\n192it [02:33,  1.16it/s]\u001b[A\n193it [02:33,  1.17it/s]\u001b[A\n194it [02:34,  1.17it/s]\u001b[A\n195it [02:35,  1.17it/s]\u001b[A\n196it [02:36,  1.18it/s]\u001b[A\n197it [02:37,  1.12it/s]\u001b[A\n198it [02:38,  1.14it/s]\u001b[A\n199it [02:39,  1.14it/s]\u001b[A\n200it [02:39,  1.16it/s]\u001b[A\n201it [02:40,  1.16it/s]\u001b[A\n202it [02:41,  1.16it/s]\u001b[A\n203it [02:42,  1.15it/s]\u001b[A\n204it [02:43,  1.15it/s]\u001b[A\n205it [02:44,  1.16it/s]\u001b[A\n206it [02:45,  1.17it/s]\u001b[A\n207it [02:45,  1.17it/s]\u001b[A\n208it [02:46,  1.12it/s]\u001b[A\n209it [02:47,  1.14it/s]\u001b[A\n210it [02:48,  1.10it/s]\u001b[A\n211it [02:49,  1.12it/s]\u001b[A\n212it [02:50,  1.13it/s]\u001b[A\n213it [02:51,  1.13it/s]\u001b[A\n214it [02:52,  1.15it/s]\u001b[A\n215it [02:53,  1.16it/s]\u001b[A\n216it [02:53,  1.15it/s]\u001b[A\n217it [02:54,  1.15it/s]\u001b[A\n218it [02:55,  1.16it/s]\u001b[A\n219it [02:56,  1.17it/s]\u001b[A\n220it [02:57,  1.17it/s]\u001b[A\n221it [02:58,  1.15it/s]\u001b[A\n222it [02:59,  1.15it/s]\u001b[A\n223it [03:00,  1.15it/s]\u001b[A\n224it [03:00,  1.15it/s]\u001b[A\n225it [03:01,  1.16it/s]\u001b[A\n226it [03:02,  1.13it/s]\u001b[A\n227it [03:03,  1.14it/s]\u001b[A\n228it [03:04,  1.14it/s]\u001b[A\n229it [03:05,  1.16it/s]\u001b[A\n230it [03:06,  1.17it/s]\u001b[A\n231it [03:06,  1.17it/s]\u001b[A\n232it [03:07,  1.17it/s]\u001b[A\n233it [03:08,  1.17it/s]\u001b[A\n234it [03:09,  1.17it/s]\u001b[A\n235it [03:10,  1.16it/s]\u001b[A\n236it [03:11,  1.17it/s]\u001b[A\n237it [03:12,  1.18it/s]\u001b[A\n238it [03:12,  1.16it/s]\u001b[A\n239it [03:13,  1.16it/s]\u001b[A\n240it [03:14,  1.15it/s]\u001b[A\n241it [03:15,  1.14it/s]\u001b[A\n242it [03:16,  1.15it/s]\u001b[A\n243it [03:17,  1.15it/s]\u001b[A\n244it [03:18,  1.15it/s]\u001b[A\n245it [03:19,  1.16it/s]\u001b[A\n246it [03:19,  1.17it/s]\u001b[A\n247it [03:20,  1.17it/s]\u001b[A\n248it [03:21,  1.17it/s]\u001b[A\n249it [03:22,  1.16it/s]\u001b[A\n250it [03:23,  1.18it/s]\u001b[A\n251it [03:24,  1.19it/s]\u001b[A\n252it [03:25,  1.14it/s]\u001b[A\n253it [03:25,  1.15it/s]\u001b[A\n254it [03:26,  1.15it/s]\u001b[A\n255it [03:27,  1.23it/s]\u001b[A\n256it [03:28,  1.22it/s]\u001b[A\n257it [03:29,  1.20it/s]\u001b[A\n258it [03:29,  1.21it/s]\u001b[A\n259it [03:30,  1.21it/s]\u001b[A\n260it [03:31,  1.14it/s]\u001b[A\n261it [03:32,  1.15it/s]\u001b[A\n262it [03:33,  1.09it/s]\u001b[A\n263it [03:34,  1.12it/s]\u001b[A\n264it [03:35,  1.15it/s]\u001b[A\n265it [03:36,  1.17it/s]\u001b[A\n266it [03:36,  1.18it/s]\u001b[A\n267it [03:37,  1.18it/s]\u001b[A\n268it [03:38,  1.18it/s]\u001b[A\n269it [03:39,  1.19it/s]\u001b[A\n270it [03:40,  1.19it/s]\u001b[A\n272it [03:41,  1.54it/s]\u001b[A\n273it [03:42,  1.44it/s]\u001b[A\n274it [03:42,  1.34it/s]\u001b[A\n275it [03:43,  1.29it/s]\u001b[A\n276it [03:44,  1.26it/s]\u001b[A\n277it [03:45,  1.24it/s]\u001b[A\n278it [03:46,  1.22it/s]\u001b[A\n279it [03:47,  1.21it/s]\u001b[A\n280it [03:48,  1.15it/s]\u001b[A\n281it [03:48,  1.15it/s]\u001b[A\n282it [03:49,  1.16it/s]\u001b[A\n283it [03:50,  1.16it/s]\u001b[A\n284it [03:51,  1.17it/s]\u001b[A\n285it [03:52,  1.16it/s]\u001b[A\n286it [03:53,  1.16it/s]\u001b[A\n287it [03:54,  1.18it/s]\u001b[A\n288it [03:54,  1.18it/s]\u001b[A\n289it [03:55,  1.18it/s]\u001b[A\n290it [03:56,  1.18it/s]\u001b[A\n291it [03:57,  1.16it/s]\u001b[A\n292it [03:58,  1.17it/s]\u001b[A\n293it [03:59,  1.16it/s]\u001b[A\n294it [04:00,  1.17it/s]\u001b[A\n295it [04:00,  1.16it/s]\u001b[A\n296it [04:01,  1.17it/s]\u001b[A\n297it [04:02,  1.14it/s]\u001b[A\n298it [04:03,  1.15it/s]\u001b[A\n299it [04:04,  1.15it/s]\u001b[A\n300it [04:05,  1.16it/s]\u001b[A\n301it [04:06,  1.10it/s]\u001b[A\n302it [04:07,  1.13it/s]\u001b[A\n303it [04:07,  1.15it/s]\u001b[A\n304it [04:08,  1.16it/s]\u001b[A\n305it [04:09,  1.16it/s]\u001b[A\n306it [04:10,  1.17it/s]\u001b[A\n307it [04:11,  1.14it/s]\u001b[A\n308it [04:12,  1.12it/s]\u001b[A\n309it [04:13,  1.14it/s]\u001b[A\n310it [04:14,  1.16it/s]\u001b[A\n312it [04:14,  1.52it/s]\u001b[A\n313it [04:15,  1.42it/s]\u001b[A\n314it [04:16,  1.35it/s]\u001b[A\n315it [04:17,  1.27it/s]\u001b[A\n316it [04:18,  1.25it/s]\u001b[A\n317it [04:19,  1.24it/s]\u001b[A\n318it [04:19,  1.24it/s]\u001b[A\n319it [04:20,  1.23it/s]\u001b[A\n320it [04:21,  1.22it/s]\u001b[A\n321it [04:22,  1.20it/s]\u001b[A\n322it [04:22,  1.52it/s]\u001b[A\n323it [04:23,  1.40it/s]\u001b[A\n324it [04:24,  1.31it/s]\u001b[A\n325it [04:25,  1.26it/s]\u001b[A\n326it [04:26,  1.22it/s]\u001b[A\n327it [04:27,  1.21it/s]\u001b[A\n328it [04:27,  1.18it/s]\u001b[A\n329it [04:28,  1.14it/s]\u001b[A\n330it [04:29,  1.13it/s]\u001b[A\n331it [04:30,  1.15it/s]\u001b[A\n332it [04:31,  1.16it/s]\u001b[A\n333it [04:32,  1.16it/s]\u001b[A\n334it [04:33,  1.17it/s]\u001b[A\n335it [04:34,  1.14it/s]\u001b[A\n336it [04:34,  1.16it/s]\u001b[A\n337it [04:35,  1.18it/s]\u001b[A\n338it [04:36,  1.17it/s]\u001b[A\n339it [04:37,  1.19it/s]\u001b[A\n340it [04:38,  1.18it/s]\u001b[A\n341it [04:39,  1.19it/s]\u001b[A\n342it [04:39,  1.20it/s]\u001b[A\n343it [04:40,  1.19it/s]\u001b[A\n344it [04:41,  1.20it/s]\u001b[A\n345it [04:42,  1.19it/s]\u001b[A\n346it [04:43,  1.16it/s]\u001b[A\n347it [04:44,  1.17it/s]\u001b[A\n348it [04:45,  1.17it/s]\u001b[A\n349it [04:45,  1.18it/s]\u001b[A\n350it [04:46,  1.17it/s]\u001b[A\n351it [04:47,  1.17it/s]\u001b[A\n352it [04:48,  1.18it/s]\u001b[A\n353it [04:49,  1.19it/s]\u001b[A\n354it [04:50,  1.20it/s]\u001b[A\n355it [04:50,  1.19it/s]\u001b[A\n356it [04:51,  1.19it/s]\u001b[A\n357it [04:52,  1.18it/s]\u001b[A\n358it [04:53,  1.18it/s]\u001b[A\n359it [04:54,  1.19it/s]\u001b[A\n360it [04:55,  1.19it/s]\u001b[A\n361it [04:55,  1.20it/s]\u001b[A\n362it [04:56,  1.20it/s]\u001b[A\n363it [04:57,  1.20it/s]\u001b[A\n364it [04:57,  1.52it/s]\u001b[A\n365it [04:58,  1.39it/s]\u001b[A\n366it [04:59,  1.32it/s]\u001b[A\n367it [05:00,  1.27it/s]\u001b[A\n368it [05:01,  1.23it/s]\u001b[A\n369it [05:02,  1.21it/s]\u001b[A\n370it [05:03,  1.19it/s]\u001b[A\n371it [05:03,  1.19it/s]\u001b[A\n372it [05:04,  1.19it/s]\u001b[A\n373it [05:05,  1.18it/s]\u001b[A\n374it [05:06,  1.18it/s]\u001b[A\n375it [05:07,  1.19it/s]\u001b[A\n376it [05:08,  1.20it/s]\u001b[A\n377it [05:08,  1.18it/s]\u001b[A\n378it [05:09,  1.17it/s]\u001b[A\n379it [05:10,  1.17it/s]\u001b[A\n380it [05:11,  1.18it/s]\u001b[A\n381it [05:12,  1.17it/s]\u001b[A\n382it [05:13,  1.18it/s]\u001b[A\n383it [05:14,  1.19it/s]\u001b[A\n384it [05:14,  1.19it/s]\u001b[A\n385it [05:15,  1.18it/s]\u001b[A\n386it [05:16,  1.18it/s]\u001b[A\n387it [05:17,  1.19it/s]\u001b[A\n388it [05:18,  1.20it/s]\u001b[A\n389it [05:19,  1.19it/s]\u001b[A\n390it [05:19,  1.20it/s]\u001b[A\n391it [05:20,  1.21it/s]\u001b[A\n392it [05:21,  1.22it/s]\u001b[A\n393it [05:22,  1.21it/s]\u001b[A\n394it [05:23,  1.21it/s]\u001b[A\n395it [05:24,  1.21it/s]\u001b[A\n396it [05:24,  1.21it/s]\u001b[A\n397it [05:25,  1.19it/s]\u001b[A\n398it [05:26,  1.19it/s]\u001b[A\n399it [05:27,  1.19it/s]\u001b[A\n400it [05:28,  1.19it/s]\u001b[A\n401it [05:29,  1.20it/s]\u001b[A\n402it [05:29,  1.20it/s]\u001b[A\n403it [05:30,  1.20it/s]\u001b[A\n404it [05:31,  1.17it/s]\u001b[A\n405it [05:32,  1.15it/s]\u001b[A\n406it [05:33,  1.14it/s]\u001b[A\n407it [05:34,  1.15it/s]\u001b[A\n408it [05:35,  1.16it/s]\u001b[A\n409it [05:35,  1.16it/s]\u001b[A\n410it [05:36,  1.15it/s]\u001b[A\n411it [05:37,  1.15it/s]\u001b[A\n412it [05:38,  1.17it/s]\u001b[A\n413it [05:39,  1.17it/s]\u001b[A\n414it [05:40,  1.19it/s]\u001b[A\n415it [05:41,  1.19it/s]\u001b[A\n416it [05:41,  1.19it/s]\u001b[A\n417it [05:42,  1.18it/s]\u001b[A\n418it [05:43,  1.18it/s]\u001b[A\n419it [05:44,  1.18it/s]\u001b[A\n420it [05:45,  1.18it/s]\u001b[A\n421it [05:46,  1.19it/s]\u001b[A\n423it [05:47,  1.45it/s]\u001b[A\n424it [05:47,  1.39it/s]\u001b[A\n425it [05:48,  1.34it/s]\u001b[A\n426it [05:49,  1.30it/s]\u001b[A\n427it [05:50,  1.27it/s]\u001b[A\n428it [05:51,  1.25it/s]\u001b[A\n429it [05:52,  1.24it/s]\u001b[A\n430it [05:53,  1.19it/s]\u001b[A\n431it [05:53,  1.19it/s]\u001b[A\n432it [05:54,  1.20it/s]\u001b[A\n433it [05:55,  1.19it/s]\u001b[A\n434it [05:56,  1.20it/s]\u001b[A\n435it [05:57,  1.20it/s]\u001b[A\n436it [05:57,  1.21it/s]\u001b[A\n437it [05:58,  1.22it/s]\u001b[A\n438it [05:59,  1.22it/s]\u001b[A\n439it [06:00,  1.22it/s]\u001b[A\n440it [06:01,  1.21it/s]\u001b[A\n441it [06:02,  1.21it/s]\u001b[A\n442it [06:02,  1.20it/s]\u001b[A\n443it [06:03,  1.20it/s]\u001b[A\n444it [06:04,  1.22it/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":" Enhanced features saved to: /kaggle/working/train_features_enhanced.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"!pip install happytransformer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T10:50:04.737528Z","iopub.execute_input":"2025-04-26T10:50:04.737771Z","iopub.status.idle":"2025-04-26T10:50:08.166684Z","shell.execute_reply.started":"2025-04-26T10:50:04.737745Z","shell.execute_reply":"2025-04-26T10:50:08.165917Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: happytransformer in /usr/local/lib/python3.11/dist-packages (3.0.0)\nRequirement already satisfied: torch>=1.0 in /usr/local/lib/python3.11/dist-packages (from happytransformer) (2.5.1+cu124)\nRequirement already satisfied: tqdm>=4.43 in /usr/local/lib/python3.11/dist-packages (from happytransformer) (4.67.1)\nRequirement already satisfied: transformers<5.0.0,>=4.30.1 in /usr/local/lib/python3.11/dist-packages (from happytransformer) (4.51.1)\nRequirement already satisfied: datasets<3.0.0,>=2.13.1 in /usr/local/lib/python3.11/dist-packages (from happytransformer) (2.21.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from happytransformer) (0.2.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from happytransformer) (3.20.3)\nRequirement already satisfied: accelerate<1.0.0,>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from happytransformer) (0.34.2)\nRequirement already satisfied: tokenizers<1.0.0,>=0.13.3 in /usr/local/lib/python3.11/dist-packages (from happytransformer) (0.21.0)\nRequirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from happytransformer) (0.19.6)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (6.0.2)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (0.30.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (0.5.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<3.0.0,>=2.13.1->happytransformer) (2024.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (3.11.16)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0->happytransformer) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.30.1->happytransformer) (2024.11.6)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (4.3.7)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (2.11.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (2.21.0)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (75.1.0)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb->happytransformer) (1.17.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (1.19.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->happytransformer) (4.0.12)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->happytransformer) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->happytransformer) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->happytransformer) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.13.1->happytransformer) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.13.1->happytransformer) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.13.1->happytransformer) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.13.1->happytransformer) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0->happytransformer) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<3.0.0,>=2.13.1->happytransformer) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<3.0.0,>=2.13.1->happytransformer) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<3.0.0,>=2.13.1->happytransformer) (2025.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->happytransformer) (5.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2024.2.0)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Ridge\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# Define features\nfeatures = [\n    'has_speech',  # Include speech flag\n    'grammar_errors', \n    'avg_sentence_length', \n    'pos_diversity',\n    'word_count', \n    'grammar_errors_per_word',\n    'gec_edits', \n    'gec_edit_rate',\n    'lexical_diversity',\n    'avg_word_length',\n    'readability_score'\n]\n\nX = enhanced_df[features]\ny = enhanced_df['label']\n\n# Split data for training\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Feature-based models\nmodel_rf = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel_lgb = lgb.LGBMRegressor(n_estimators=100, random_state=42)\nmodel_ridge = Ridge(alpha=1.0)\n\n# Train models\nmodel_rf.fit(X_train, y_train)\nmodel_lgb.fit(X_train, y_train)\nmodel_ridge.fit(X_train, y_train)\n\n# Predict on validation\npred_rf = model_rf.predict(X_val)\npred_lgb = model_lgb.predict(X_val)\npred_ridge = model_ridge.predict(X_val)\n\n# Ensemble (averaged predictions)\nensemble_feat_preds = (pred_rf + pred_lgb + pred_ridge) / 3\n\n# Evaluation\nmae = mean_absolute_error(y_val, ensemble_feat_preds)\nrmse = np.sqrt(mean_squared_error(y_val, ensemble_feat_preds))\ncorr, _ = pearsonr(y_val, ensemble_feat_preds)\n\nprint(f\" Feature Ensemble MAE: {mae:.3f}\")\nprint(f\" Feature Ensemble RMSE: {rmse:.3f}\")\nprint(f\" Feature Ensemble Pearson Correlation: {corr:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T10:50:08.167732Z","iopub.execute_input":"2025-04-26T10:50:08.168000Z","iopub.status.idle":"2025-04-26T10:50:10.562780Z","shell.execute_reply.started":"2025-04-26T10:50:08.167976Z","shell.execute_reply":"2025-04-26T10:50:10.562091Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000884 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 902\n[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 10\n[LightGBM] [Info] Start training from score 4.001408\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n Feature Ensemble MAE: 0.839\n Feature Ensemble RMSE: 1.065\n Feature Ensemble Pearson Correlation: 0.420\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom datasets import Dataset\nimport torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport os\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n# Prepare text data for transformer model\ntext_df = enhanced_df[['cleaned_transcript', 'label', 'has_speech']]\ntext_df = text_df.rename(columns={'cleaned_transcript': 'text'})\n\n# Split for transformer model\ntrain_text, val_text = train_test_split(text_df, test_size=0.2, random_state=42)\n\n# Create HuggingFace datasets\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\ntrain_hf = Dataset.from_pandas(train_text[['text', 'label']])\nval_hf = Dataset.from_pandas(val_text[['text', 'label']])\ntrain_hf = train_hf.map(tokenize)\nval_hf = val_hf.map(tokenize)\ntrain_hf = train_hf.rename_column(\"label\", \"labels\")\nval_hf = val_hf.rename_column(\"label\", \"labels\")\n\n# DistilBERT for regression\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert-base-uncased\", num_labels=1\n)\n\n# Metrics calculation\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    preds = predictions.squeeze()\n    mse = ((preds - labels) ** 2).mean()\n    mae = np.abs(preds - labels).mean()\n    corr = np.corrcoef(preds, labels)[0, 1]\n    return {\"mae\": mae, \"mse\": mse, \"pearson\": corr}\n\n# Training arguments for version 4.51.1\n# Training arguments for version 4.51.1\nargs = TrainingArguments(\n    output_dir=\"./bert-regressor\",\n    eval_steps=25,\n    logging_steps=25,\n    save_steps=0,  # equivalent to save_strategy=\"no\"\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=8,\n    num_train_epochs=12,\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    disable_tqdm=False,\n    report_to=\"none\",  # Using string \"none\" instead of None\n    dataloader_pin_memory=False,\n)\n\n# Set device\nif torch.cuda.is_available():\n    model.to(\"cuda\")\n    print(\" Model on GPU\")\n\n# Create trainer and train\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_hf,\n    eval_dataset=val_hf,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\n\n# Get transformer predictions on validation set\nbert_preds_val = trainer.predict(val_hf).predictions.squeeze()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T10:50:10.563555Z","iopub.execute_input":"2025-04-26T10:50:10.564541Z","iopub.status.idle":"2025-04-26T10:51:08.468481Z","shell.execute_reply.started":"2025-04-26T10:50:10.564518Z","shell.execute_reply":"2025-04-26T10:51:08.467706Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26fe86061c9b443f87c09ccf9f590aa4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b467d1e8f664809bdff72a7d581d2e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f47c67127744e289e8dffb412c9164f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e57d055588da4a0fafe1ffb883046c7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/355 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cade321c57874231a910379d8aae0e6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/89 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0226193eb53742b9a521e3b4f5a24b9a"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf6b996b1fb842d0949524020b214770"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":" Model on GPU\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1068' max='1068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1068/1068 00:51, Epoch 12/12]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>8.295800</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.481900</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.927100</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.158300</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.991500</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.866000</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>0.688000</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.647500</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>0.602700</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.383600</td>\n    </tr>\n    <tr>\n      <td>275</td>\n      <td>0.528400</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.332800</td>\n    </tr>\n    <tr>\n      <td>325</td>\n      <td>0.442200</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.261700</td>\n    </tr>\n    <tr>\n      <td>375</td>\n      <td>0.232700</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.330100</td>\n    </tr>\n    <tr>\n      <td>425</td>\n      <td>0.197800</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.182300</td>\n    </tr>\n    <tr>\n      <td>475</td>\n      <td>0.234700</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.246200</td>\n    </tr>\n    <tr>\n      <td>525</td>\n      <td>0.138200</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.143400</td>\n    </tr>\n    <tr>\n      <td>575</td>\n      <td>0.127500</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.159500</td>\n    </tr>\n    <tr>\n      <td>625</td>\n      <td>0.230500</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.176700</td>\n    </tr>\n    <tr>\n      <td>675</td>\n      <td>0.156700</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.116600</td>\n    </tr>\n    <tr>\n      <td>725</td>\n      <td>0.100500</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.083200</td>\n    </tr>\n    <tr>\n      <td>775</td>\n      <td>0.211300</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.096500</td>\n    </tr>\n    <tr>\n      <td>825</td>\n      <td>0.098800</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.078600</td>\n    </tr>\n    <tr>\n      <td>875</td>\n      <td>0.185900</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.111300</td>\n    </tr>\n    <tr>\n      <td>925</td>\n      <td>0.182300</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.066700</td>\n    </tr>\n    <tr>\n      <td>975</td>\n      <td>0.067900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.108800</td>\n    </tr>\n    <tr>\n      <td>1025</td>\n      <td>0.074300</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.136200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# ======== META ENSEMBLE ========\n\nfrom sklearn.linear_model import LinearRegression\n\n# Stack predictions from both model types\nstacked_val = np.vstack([bert_preds_val, ensemble_feat_preds]).T\n\n# Train meta-regressor\nmeta_model = LinearRegression()\nmeta_model.fit(stacked_val, y_val)\n\n# Final predictions with meta-ensemble\nfinal_val_preds = meta_model.predict(stacked_val)\n\n# Handle non-speech cases specially\nfor i, has_speech in enumerate(val_text['has_speech'].values):\n    if not has_speech:\n        # Calculate default score for non-speech from training\n        nonspeech_default = enhanced_df[~enhanced_df['has_speech']]['label'].median() if sum(~enhanced_df['has_speech']) > 0 else 3\n        final_val_preds[i] = nonspeech_default\n\n# Final evaluation\nmae = mean_absolute_error(y_val, final_val_preds)\nrmse = np.sqrt(mean_squared_error(y_val, final_val_preds))\npearson = pearsonr(y_val, final_val_preds)[0]\n\nprint(f\" Final Meta-Ensemble MAE: {mae:.3f}\")\nprint(f\" Final Meta-Ensemble RMSE: {rmse:.3f}\")\nprint(f\" Final Meta-Ensemble Pearson: {pearson:.3f}\")\n# === Save all trained models ===\n\nimport joblib\nimport torch\n\n# Save feature-based models\njoblib.dump(model_rf, 'random_forest_model.pkl')\njoblib.dump(model_lgb, 'lgbm_model.pkl')\njoblib.dump(model_ridge, 'ridge_model.pkl')\n\n# Save Transformer (BERT) model\ntorch.save(model.state_dict(), 'bert_regressor.pth')\n\n# Save Meta model\njoblib.dump(meta_model, 'meta_ensemble_model.pkl')\n\nprint(\" All models saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T10:51:08.469466Z","iopub.execute_input":"2025-04-26T10:51:08.469685Z","iopub.status.idle":"2025-04-26T10:51:08.936491Z","shell.execute_reply.started":"2025-04-26T10:51:08.469666Z","shell.execute_reply":"2025-04-26T10:51:08.935675Z"}},"outputs":[{"name":"stdout","text":" Final Meta-Ensemble MAE: 0.609\n Final Meta-Ensemble RMSE: 0.824\n Final Meta-Ensemble Pearson: 0.706\n All models saved successfully!\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Define test paths\nTEST_AUDIO_DIR = '/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test'\nTEST_CSV_PATH = '/kaggle/input/shl-intern-hiring-assessment/Dataset/test.csv'\nTEST_PROCESSED_DIR = '/kaggle/working/processed_test_audio'\nos.makedirs(TEST_PROCESSED_DIR, exist_ok=True)\n\n# Load test data\ntest_df = pd.read_csv(TEST_CSV_PATH)\n\n# Process test audio\nspeech_flags_test = []\nfor filename in tqdm(test_df['filename']):\n    in_path = os.path.join(TEST_AUDIO_DIR, filename)\n    out_path = os.path.join(TEST_PROCESSED_DIR, filename)\n    \n    preprocess_audio(in_path, out_path)\n    has_speech = detect_speech_content(out_path)\n    speech_flags_test.append(has_speech)\n\ntest_df['has_speech'] = speech_flags_test\n\n# Transcribe test audio\ntranscripts_test = []\nfor idx, row in tqdm(test_df.iterrows()):\n    fname = row['filename']\n    audio_path = os.path.join(TEST_PROCESSED_DIR, fname)\n    \n    if row['has_speech']:\n        result = whisper_model.transcribe(audio_path, language='en')\n        transcript = result['text']\n    else:\n        transcript = \"\"\n        \n    transcripts_test.append(transcript)\n\ntest_df['transcript'] = transcripts_test\n\n# Clean test transcripts\ntest_df['cleaned_transcript'] = test_df['transcript'].apply(clean_transcript)\n\n# Save cleaned test data\ntest_df.to_csv('/kaggle/working/test_cleaned.csv', index=False)\nprint(\" Cleaned test transcripts saved.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T10:51:08.937464Z","iopub.execute_input":"2025-04-26T10:51:08.937898Z","iopub.status.idle":"2025-04-26T11:03:21.310627Z","shell.execute_reply.started":"2025-04-26T10:51:08.937844Z","shell.execute_reply":"2025-04-26T11:03:21.309795Z"}},"outputs":[{"name":"stderr","text":"100%|| 204/204 [03:15<00:00,  1.04it/s]\n204it [08:56,  2.63s/it]","output_type":"stream"},{"name":"stdout","text":" Cleaned test transcripts saved.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Extract features for test set\ntest_features = []\nfor idx, row in tqdm(test_df.iterrows()):\n    text = row['cleaned_transcript']\n    has_speech = row['has_speech']\n    features = extract_enhanced_features(text, has_speech)\n    test_features.append(features)\n# Convert to DataFrame and merge with test data\ntest_features_df = pd.DataFrame(test_features)\ntest_enhanced_df = pd.concat([test_df, test_features_df], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T11:03:21.311581Z","iopub.execute_input":"2025-04-26T11:03:21.311905Z","iopub.status.idle":"2025-04-26T11:06:08.926807Z","shell.execute_reply.started":"2025-04-26T11:03:21.311876Z","shell.execute_reply":"2025-04-26T11:06:08.925903Z"}},"outputs":[{"name":"stderr","text":"204it [02:47,  1.22it/s]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# ======== PREDICT ON TEST SET ========\n\n# Prepare test data for transformer model\ntest_hf = Dataset.from_pandas(test_df[['cleaned_transcript']].rename(columns={\"cleaned_transcript\": \"text\"}))\ntest_hf = test_hf.map(tokenize)\n\n# Get transformer predictions\nbert_test_preds = trainer.predict(test_hf).predictions.squeeze()\n\n# Get feature-based predictions\n# Match training features exactly\ntraining_feature_cols = model_rf.feature_names_in_  # Automatically stores features seen at .fit()\nX_test_feat = test_enhanced_df[training_feature_cols]\n\n\npred_rf_test = model_rf.predict(X_test_feat)\npred_lgb_test = model_lgb.predict(X_test_feat)\npred_ridge_test = model_ridge.predict(X_test_feat)\nensemble_feat_test_preds = (pred_rf_test + pred_lgb_test + pred_ridge_test) / 3\n\n# Stack and apply meta-regressor\nstacked_test_preds = np.vstack([bert_test_preds, ensemble_feat_test_preds]).T\nfinal_test_preds = meta_model.predict(stacked_test_preds)\n\n# Special handling for non-speech files\nnonspeech_default = enhanced_df[~enhanced_df['has_speech']]['label'].median() if sum(~enhanced_df['has_speech']) > 0 else 3\nfor i, has_speech in enumerate(test_df['has_speech']):\n    if not has_speech:\n        final_test_preds[i] = nonspeech_default\n\ntest_df['label'] = (np.round(final_test_preds * 2) / 2).clip(0, 5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T11:06:08.927740Z","iopub.execute_input":"2025-04-26T11:06:08.928271Z","iopub.status.idle":"2025-04-26T11:06:09.588482Z","shell.execute_reply.started":"2025-04-26T11:06:08.928245Z","shell.execute_reply":"2025-04-26T11:06:09.587679Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/204 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"195a607b565343de86394628eca068c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# ======== GENERATE SUBMISSION ========\n\nsubmission = test_df[['filename', 'label']]\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T11:06:09.589370Z","iopub.execute_input":"2025-04-26T11:06:09.589611Z","iopub.status.idle":"2025-04-26T11:06:09.595454Z","shell.execute_reply.started":"2025-04-26T11:06:09.589593Z","shell.execute_reply":"2025-04-26T11:06:09.594868Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}