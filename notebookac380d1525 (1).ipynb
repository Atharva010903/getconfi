{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":97919,"databundleVersionId":11872932,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:52:42.074867Z","iopub.execute_input":"2025-04-21T18:52:42.075163Z","iopub.status.idle":"2025-04-21T18:52:43.008985Z","shell.execute_reply.started":"2025-04-21T18:52:42.075141Z","shell.execute_reply":"2025-04-21T18:52:43.008242Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"/kaggle/input/shl-intern-hiring-assessment/Dataset/sample_submission.csv\n/kaggle/input/shl-intern-hiring-assessment/Dataset/train.csv\n/kaggle/input/shl-intern-hiring-assessment/Dataset/test.csv\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_885.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1142.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1006.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_817.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_765.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_508.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_257.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_330.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_72.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_328.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_858.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_464.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_505.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_853.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1001.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_855.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_995.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_472.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1028.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_550.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_841.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_256.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_641.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1131.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_234.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_284.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_188.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1220.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_67.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_818.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_967.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_709.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_872.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1165.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_415.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_714.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1231.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_430.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_27.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1207.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_922.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_976.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1180.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_327.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1212.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1092.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1270.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1163.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1041.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_940.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_563.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_661.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_220.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_57.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1136.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1179.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_41.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_590.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1294.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_161.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1069.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_261.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1246.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_89.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_952.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_846.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_909.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1088.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_989.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_865.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_278.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1300.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_298.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_178.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_674.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1104.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_966.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1134.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1079.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1329.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_542.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_954.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_171.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_530.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_822.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_14.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_689.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_309.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1046.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_502.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_568.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_80.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_13.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_668.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1170.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_47.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_218.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1316.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_904.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_268.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_130.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_273.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_962.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1226.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_452.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_585.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1286.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_692.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_357.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_335.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_681.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1186.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_766.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_686.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1099.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_339.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_534.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_531.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1326.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_397.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1218.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_453.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_670.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1090.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1102.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_24.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_978.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_746.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1158.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_682.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_324.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_358.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_377.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_744.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_249.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_956.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_854.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_981.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_245.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_903.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_749.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_929.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_529.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_828.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_236.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_200.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_935.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1200.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_353.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1055.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1255.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_501.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_947.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1217.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_804.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_168.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_701.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_117.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_780.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1059.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_390.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_599.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_153.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_988.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_241.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_481.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_652.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_483.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_787.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1291.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1258.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1039.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_902.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_373.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1138.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1025.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_647.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1225.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1011.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_108.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_34.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_938.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_376.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_769.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_554.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_407.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_99.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_449.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_548.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_664.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_33.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_248.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_774.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_827.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_748.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_301.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_128.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_637.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_267.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_915.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1166.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_450.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_612.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/audio_1187.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_698.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1176.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_77.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1215.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_66.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_894.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_54.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1232.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_694.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_237.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1032.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_688.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_752.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_596.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_638.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_886.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_711.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_741.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_936.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_538.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1271.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_859.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_845.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_821.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_164.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1266.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1005.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1036.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_994.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_760.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_315.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1284.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1152.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_843.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_25.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_950.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1199.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_753.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1322.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1224.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_7.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1100.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1157.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_406.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_321.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_20.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_59.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_802.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_518.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1310.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_12.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_591.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_348.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1082.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_537.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_444.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_959.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_404.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_254.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_338.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_990.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_233.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_539.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_276.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1323.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_157.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_778.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_354.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_29.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_676.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_37.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_454.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_811.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1183.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_946.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_600.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1277.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_901.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_199.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1336.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1297.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_308.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_251.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_232.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1054.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_631.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_495.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_265.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1098.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_662.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_558.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_900.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_470.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_673.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_964.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_633.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_418.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_274.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_280.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_486.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1337.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_231.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_567.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_374.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1194.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_944.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_856.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1084.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_230.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1306.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_120.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_295.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_297.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_899.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_516.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_56.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1103.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_346.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1007.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_446.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_189.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1236.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_277.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_957.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_491.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1012.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_190.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_759.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_642.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_347.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_824.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_851.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_457.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1253.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1171.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_773.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_76.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_905.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1015.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_205.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_361.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1035.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1159.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_497.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_928.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_102.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_399.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_296.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_860.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_942.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_881.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_499.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1116.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_393.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_275.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_779.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1278.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_370.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_410.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1197.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_565.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_807.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1241.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_4.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_356.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_162.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_118.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1202.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_974.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_366.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_743.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_210.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_19.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1228.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_998.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1018.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_614.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_396.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1239.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_583.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1114.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_771.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1049.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_829.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1058.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1182.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1094.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_719.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1205.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_930.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_801.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1091.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_217.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_84.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_575.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_475.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1045.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_258.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_23.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_593.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_592.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_423.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1237.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_916.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_159.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_522.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_545.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_387.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_266.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_372.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_784.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1133.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_93.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_331.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_849.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_934.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_215.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_826.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_659.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_364.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_654.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1083.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_174.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_816.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_987.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_5.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_551.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1120.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1128.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1066.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1119.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1221.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_628.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_622.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_763.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_355.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_553.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_85.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_574.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_182.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_756.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_800.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_38.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_469.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_965.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_148.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_127.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_677.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_434.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_691.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1075.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1030.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_239.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_252.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_871.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_326.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_288.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_98.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1105.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_286.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_263.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_209.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_656.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_302.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_984.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_52.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_16.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_844.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_460.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1111.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_594.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_679.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1076.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_764.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_332.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1151.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1335.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1173.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_78.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_388.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_700.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_224.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_939.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1282.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1002.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_375.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_383.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_996.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_921.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_515.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_30.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_745.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_216.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1192.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1219.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_949.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_459.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_362.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_908.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_482.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_158.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1042.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_219.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1309.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_533.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_154.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_958.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1249.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_805.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_630.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_730.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_611.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_92.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_69.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_385.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_221.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_131.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_336.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_880.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_707.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1238.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1330.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_742.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_292.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_754.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_716.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1276.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_985.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1161.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_840.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1029.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_68.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_671.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_432.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1078.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_155.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_378.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_264.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_360.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_349.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1240.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_212.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_183.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_474.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_419.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_316.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1332.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_242.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_667.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1254.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1072.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1132.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_825.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_586.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_226.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_426.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1019.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_39.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_890.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_197.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_213.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1168.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1290.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1339.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_136.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_893.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1314.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_687.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_312.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_147.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_783.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_144.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_710.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_706.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_573.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1214.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_139.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_503.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_134.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_18.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_116.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_789.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1087.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_523.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_420.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1156.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_135.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1223.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_325.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_556.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_669.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_755.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_973.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_678.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_655.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1265.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_250.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1299.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1174.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_512.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_150.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_392.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_73.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_43.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_712.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_437.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_613.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_493.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_704.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_431.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_3.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_832.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_428.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_658.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_58.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_471.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1117.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_713.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_768.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_640.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1023.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_566.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1135.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_36.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_201.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_74.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1320.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1127.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_993.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_480.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_560.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_877.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_852.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1096.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_514.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_696.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_1234.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_151.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_557.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_473.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_651.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_724.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_259.wav\n/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/audio_795.wav\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"#importing all basic libraries required in code\nimport numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport librosa\nimport soundfile as sf\nfrom tqdm.notebook import tqdm\nimport re\nimport torch\nfrom scipy.stats import pearsonr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:52:43.010576Z","iopub.execute_input":"2025-04-21T18:52:43.011055Z","iopub.status.idle":"2025-04-21T18:52:43.014763Z","shell.execute_reply.started":"2025-04-21T18:52:43.011031Z","shell.execute_reply":"2025-04-21T18:52:43.014140Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"!pip install librosa pydub openai-whisper transformers sentencepiece torch pandas scikit-learn language-tool-python spacy nltk happytransformer\n!python -m spacy download en_core_web_sm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:52:43.015465Z","iopub.execute_input":"2025-04-21T18:52:43.015659Z","iopub.status.idle":"2025-04-21T18:52:54.418452Z","shell.execute_reply.started":"2025-04-21T18:52:43.015644Z","shell.execute_reply":"2025-04-21T18:52:54.417437Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\nRequirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (20240930)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: language-tool-python in /usr/local/lib/python3.11/dist-packages (2.7.1)\nRequirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: happytransformer in /usr/local/lib/python3.11/dist-packages (3.0.0)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\nRequirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\nRequirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.2)\nRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\nRequirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\nRequirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\nRequirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\nRequirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.1)\nRequirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\nRequirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\nRequirement already satisfied: datasets<3.0.0,>=2.13.1 in /usr/local/lib/python3.11/dist-packages (from happytransformer) (2.21.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from happytransformer) (3.20.3)\nRequirement already satisfied: accelerate<1.0.0,>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from happytransformer) (0.34.2)\nRequirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from happytransformer) (0.19.6)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (7.0.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (0.3.8)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (0.70.16)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (3.11.16)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (3.1.44)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (2.21.0)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (1.3.4)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (1.19.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->happytransformer) (4.0.12)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2024.2.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->happytransformer) (5.0.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting en-core-web-sm==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.33.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.13.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"import transformers\nprint(transformers.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:52:54.419771Z","iopub.execute_input":"2025-04-21T18:52:54.420464Z","iopub.status.idle":"2025-04-21T18:52:54.424775Z","shell.execute_reply.started":"2025-04-21T18:52:54.420438Z","shell.execute_reply":"2025-04-21T18:52:54.424230Z"}},"outputs":[{"name":"stdout","text":"4.51.1\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"## Create processed audio directory and load training CSV with renamed columns\n\nAUDIO_DIR = '/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train'\nCSV_PATH = '/kaggle/input/shl-intern-hiring-assessment/Dataset/train.csv'\nPROCESSED_DIR = '/kaggle/working/processed_audio'\nos.makedirs(PROCESSED_DIR, exist_ok=True)\n\n# Load CSV and rename columns\ntrain_df = pd.read_csv(CSV_PATH)\ntrain_df.columns = ['filename', 'label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:52:54.426831Z","iopub.execute_input":"2025-04-21T18:52:54.427125Z","iopub.status.idle":"2025-04-21T18:52:54.448243Z","shell.execute_reply.started":"2025-04-21T18:52:54.427108Z","shell.execute_reply":"2025-04-21T18:52:54.447466Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"## Detect whether an audio file contains speech by analyzing silence, speech ratio, and zero-crossing rate variation\n\ndef detect_speech_content(audio_path):\n    \"\"\"Determine if audio contains speech or just instrumental/noise\"\"\"\n    y, sr = librosa.load(audio_path, sr=16000)\n    \n    # Multiple detection methods\n    non_silence = librosa.effects.split(y, top_db=25)\n    speech_ratio = sum(end-start for start, end in non_silence) / len(y) if len(y) > 0 else 0\n    \n    # Zero-crossing rate variance (speech has more variation than music)\n    zcr = librosa.feature.zero_crossing_rate(y)[0]\n    zcr_std = np.std(zcr)\n    \n    # Combined check\n    has_speech = speech_ratio > 0.1 and zcr_std > 0.05\n    return has_speech","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:52:54.449034Z","iopub.execute_input":"2025-04-21T18:52:54.449252Z","iopub.status.idle":"2025-04-21T18:52:54.454611Z","shell.execute_reply.started":"2025-04-21T18:52:54.449229Z","shell.execute_reply":"2025-04-21T18:52:54.454015Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# Function: Preprocess audio by resampling, normalizing volume, and trimming silence\ndef preprocess_audio(file_path, save_path, sr=16000):\n    \"\"\"Enhanced preprocessing with speech detection\"\"\"\n    y, orig_sr = librosa.load(file_path, sr=None)\n    if orig_sr != sr:\n        y = librosa.resample(y, orig_sr, sr)\n    \n    # Normalize volume\n    y = y / max(abs(y)) if max(abs(y)) > 0 else y\n    \n    # Trim silence\n    y, _ = librosa.effects.trim(y, top_db=25)\n    sf.write(save_path, y, sr)\n# Function: Detect whether an audio contains speech using silence trimming and ZCR variation\n# Process each audio file\n\n# Important: Preprocessing each audio file and detecting speech before transcription\nspeech_flags = []\nfor filename in tqdm(train_df['filename']):\n    in_path = os.path.join(AUDIO_DIR, filename)\n    out_path = os.path.join(PROCESSED_DIR, filename)\n    \n    # Original preprocessing\n    preprocess_audio(in_path, out_path)\n    \n    # Add speech detection\n    has_speech = detect_speech_content(out_path)\n    speech_flags.append(has_speech)\n\n# Add speech flag to dataframe\ntrain_df['has_speech'] = speech_flags\n\n# Report number of non-speech files (useful for understanding audio content distribution)\nnon_speech_count = sum(1 for flag in speech_flags if not flag)\nprint(f\"📊 Detected {non_speech_count}/{len(speech_flags)} files as non-speech/instrumental\")\n\n# Check sample rate and duration of a random file\nfiles = os.listdir(PROCESSED_DIR)\nprint(f\"🔎 Found {len(files)} preprocessed audio files.\\nExample files:\\n\", files[:5])\n\nsample_file = os.path.join(PROCESSED_DIR, files[0])\ny, sr = librosa.load(sample_file, sr=None)\n\nduration = librosa.get_duration(y=y, sr=sr)\nprint(f\"📁 Sample file: {files[0]}\")\nprint(f\"🕒 Duration: {duration:.2f} seconds\")\nprint(f\"🎧 Sample rate: {sr} Hz\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:52:54.455385Z","iopub.execute_input":"2025-04-21T18:52:54.455623Z","iopub.status.idle":"2025-04-21T18:59:28.701955Z","shell.execute_reply.started":"2025-04-21T18:52:54.455607Z","shell.execute_reply":"2025-04-21T18:59:28.701375Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/444 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e79d77f61094b17b498991c4114f28a"}},"metadata":{}},{"name":"stdout","text":"📊 Detected 13/444 files as non-speech/instrumental\n🔎 Found 444 preprocessed audio files.\nExample files:\n ['audio_69.wav', 'audio_77.wav', 'audio_491.wav', 'audio_936.wav', 'audio_1215.wav']\n📁 Sample file: audio_69.wav\n🕒 Duration: 54.27 seconds\n🎧 Sample rate: 16000 Hz\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# Load Whisper ASR model for transcription\nimport whisper\n\n# Load Whisper ASR model\nwhisper_model= whisper.load_model(\"base\")  # Options: tiny, base, small, medium, large\n\n#  Important: Transcribe only speech-containing files to save compute and avoid noise\ntranscripts = []\n\nfor idx, row in tqdm(train_df.iterrows()):\n    fname = row['filename']\n    audio_path = os.path.join(PROCESSED_DIR, fname)\n    \n    if row['has_speech']:\n        # Normal transcription for speech files\n        result = whisper_model.transcribe(audio_path, language='en')\n        transcript = result['text']\n    else:\n        # Skip transcription for non-speech files\n        transcript = \"\"\n    \n    transcripts.append(transcript)\n\n# Add transcripts to dataframe\ntrain_df['transcript'] = transcripts\n\n# Save updated CSV\ntrain_df.to_csv('/kaggle/working/train_with_transcripts.csv', index=False)\nprint(\"✅ Transcriptions saved to: /kaggle/working/train_with_transcripts.csv\")\n\n# Sample transcript review\ndf = pd.read_csv('/kaggle/working/train_with_transcripts.csv')\nprint(\"🧾 Columns:\", df.columns.tolist())\nprint(\"✅ Total records:\", len(df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T20:05:15.577733Z","iopub.execute_input":"2025-04-21T20:05:15.578086Z","iopub.status.idle":"2025-04-21T20:29:05.237635Z","shell.execute_reply.started":"2025-04-21T20:05:15.578064Z","shell.execute_reply":"2025-04-21T20:29:05.236814Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(fp, map_location=device)\n444it [23:48,  3.22s/it]","output_type":"stream"},{"name":"stdout","text":"✅ Transcriptions saved to: /kaggle/working/train_with_transcripts.csv\n🧾 Columns: ['filename', 'label', 'has_speech', 'transcript']\n✅ Total records: 444\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"🖥️ Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T20:31:00.056593Z","iopub.execute_input":"2025-04-21T20:31:00.056900Z","iopub.status.idle":"2025-04-21T20:31:00.061488Z","shell.execute_reply.started":"2025-04-21T20:31:00.056879Z","shell.execute_reply":"2025-04-21T20:31:00.060711Z"}},"outputs":[{"name":"stdout","text":"🖥️ Using device: cuda\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"FILLERS = ['uh', 'um', 'erm', 'you know', 'like', 'i mean', 'hmm', 'ah', 'uhh', 'huh']\n\ndef clean_transcript(text):\n    text = text.lower()  # Standard casing\n    text = re.sub(r'\\b(?:' + '|'.join(FILLERS) + r')\\b', '', text)  # Remove fillers\n    text = re.sub(r'\\s+', ' ', text)  # Collapse multiple spaces\n    text = re.sub(r'\\s([?.!,\"])', r'\\1', text)  # Remove space before punctuation\n    text = text.strip()\n    return text\n\n# Clean all transcripts\ndf['cleaned_transcript'] = df['transcript'].astype(str).apply(clean_transcript)\n\n# Save new version\ndf.to_csv('/kaggle/working/train_cleaned.csv', index=False)\nprint(\"✅ Cleaned transcripts saved to: /kaggle/working/train_cleaned.csv\")\nprint(df[['transcript', 'cleaned_transcript']].sample(3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T20:31:02.668167Z","iopub.execute_input":"2025-04-21T20:31:02.668851Z","iopub.status.idle":"2025-04-21T20:31:02.725177Z","shell.execute_reply.started":"2025-04-21T20:31:02.668828Z","shell.execute_reply":"2025-04-21T20:31:02.724460Z"}},"outputs":[{"name":"stdout","text":"✅ Cleaned transcripts saved to: /kaggle/working/train_cleaned.csv\n                                            transcript  \\\n334   The sun is shining bright, the sun is shining...   \n137   So the best day of my life is when I went to ...   \n72    The best day that happened in my life is when...   \n\n                                    cleaned_transcript  \n334  the sun is shining bright, the sun is shining ...  \n137  so the best day of my life is when i went to d...  \n72   the best day that happened in my life is when ...  \n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"!pip install language-tool-python==2.7.1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T20:31:10.069645Z","iopub.execute_input":"2025-04-21T20:31:10.070380Z","iopub.status.idle":"2025-04-21T20:31:13.052306Z","shell.execute_reply.started":"2025-04-21T20:31:10.070352Z","shell.execute_reply":"2025-04-21T20:31:13.051559Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: language-tool-python==2.7.1 in /usr/local/lib/python3.11/dist-packages (2.7.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language-tool-python==2.7.1) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from language-tool-python==2.7.1) (4.67.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python==2.7.1) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python==2.7.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python==2.7.1) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->language-tool-python==2.7.1) (2025.1.31)\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"!apt-get update\n!apt-get install -y openjdk-11-jdk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T20:31:17.256104Z","iopub.execute_input":"2025-04-21T20:31:17.256742Z","iopub.status.idle":"2025-04-21T20:31:22.677153Z","shell.execute_reply.started":"2025-04-21T20:31:17.256713Z","shell.execute_reply":"2025-04-21T20:31:22.676167Z"}},"outputs":[{"name":"stdout","text":"0% [Working]","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\nHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease         \nGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]                           \nHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease                                              \nHit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease                                          \nGet:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]                             \nHit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\nHit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\nHit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\nHit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\nFetched 257 kB in 1s (198 kB/s)\nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... 0%\r","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nopenjdk-11-jdk is already the newest version (11.0.26+4-1ubuntu1~22.04).\n0 upgraded, 0 newly installed, 0 to remove and 146 not upgraded.\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"import spacy\nfrom happytransformer import HappyTextToText, TTSettings\nimport re\nfrom tqdm import tqdm\nimport pandas as pd\n\n# Load NLP model\ntry:\n    nlp = spacy.load(\"en_core_web_sm\")\nexcept:\n    # If model isn't installed, download it\n    import spacy.cli\n    spacy.cli.download(\"en_core_web_sm\")\n    nlp = spacy.load(\"en_core_web_sm\")\n\n# Load text correction model\nhappy_tt = HappyTextToText(\"T5\", \"vennify/t5-base-grammar-correction\")\nargs = TTSettings(\n    num_beams=5,\n    do_sample=False,\n    temperature=1.0,\n    top_k=50,\n    top_p=1.0\n)\ndef simple_grammar_check(text):\n    \"\"\"Simple rule-based grammar checker to replace LanguageTool\"\"\"\n    errors = 0\n    \n    # Check for common grammar issues\n    # Double spaces\n    errors += len(re.findall(r\"  +\", text))\n    \n    # Missing period at end of sentence\n    errors += len(re.findall(r\"[a-zA-Z]$\", text))\n    \n    # Missing capitalization after period\n    errors += len(re.findall(r\"\\. [a-z]\", text))\n    \n    # Double punctuation\n    errors += len(re.findall(r\"[,.!?]{2,}\", text))\n    \n    # Common spelling mistakes (very basic)\n    common_mistakes = [\"teh\", \"alot\", \"definately\", \"occured\", \"recieve\", \n                       \"seperate\", \"wierd\", \"accomodate\", \"goverment\", \"wich\"]\n    \n    for mistake in common_mistakes:\n        errors += len(re.findall(r\"\\b\" + mistake + r\"\\b\", text.lower()))\n    \n    return errors\n\ndef extract_enhanced_features(text, has_speech=True):\n    \"\"\"Extract comprehensive linguistic features with special handling for non-speech\"\"\"\n    features = {}\n    \n    # Special case for non-speech or empty text\n    if not has_speech or not text.strip():\n        features['is_empty'] = 1\n        features['grammar_errors'] = 0\n        features['avg_sentence_length'] = 0\n        features['pos_diversity'] = 0\n        features['word_count'] = 0\n        features['grammar_errors_per_word'] = 0\n        features['gec_edits'] = 0\n        features['gec_edit_rate'] = 0\n        features['lexical_diversity'] = 0\n        features['avg_word_length'] = 0\n        features['readability_score'] = 0\n        return features\n    \n    # Text is not empty, extract normal features\n    doc = nlp(text)\n    \n    # Regular features\n    features['is_empty'] = 0\n    features['grammar_errors'] = simple_grammar_check(text)  # Using our custom checker\n    \n    # Calculate sentence lengths\n    sentences = list(doc.sents)\n    if sentences:\n        sent_lengths = [len(sent) for sent in sentences]\n        features['avg_sentence_length'] = sum(sent_lengths) / len(sent_lengths)\n    else:\n        features['avg_sentence_length'] = 0\n    \n    pos_tags = [token.pos_ for token in doc if token.pos_ != 'SPACE']\n    features['pos_diversity'] = len(set(pos_tags)) if pos_tags else 0\n\n    # Word count and error rate\n    words = text.split()\n    features['word_count'] = len(words)\n    features['grammar_errors_per_word'] = features['grammar_errors'] / max(1, features['word_count'])\n    \n    # GEC features - grammar correction edits\n    if text.strip():\n        corrected = happy_tt.generate_text(\"grammar: \" + text).text\n        corrected_words = corrected.split()\n        \n        # Calculate edits\n        min_len = min(len(words), len(corrected_words))\n        edits = sum(1 for i in range(min_len) if words[i] != corrected_words[i])\n        edits += abs(len(words) - len(corrected_words))\n        \n        features['gec_edits'] = edits\n        features['gec_edit_rate'] = edits / max(1, len(words))\n    else:\n        features['gec_edits'] = 0\n        features['gec_edit_rate'] = 0\n    \n    # Enhanced features\n    # Lexical diversity (unique words / total words)\n    unique_words = len(set([token.text.lower() for token in doc if token.is_alpha]))\n    features['lexical_diversity'] = unique_words / max(1, features['word_count'])\n    \n    # Average word length\n    features['avg_word_length'] = sum(len(w) for w in words) / max(1, len(words))\n    \n    # Readability score (simplified Flesch)\n    features['readability_score'] = 206.835 - (1.015 * features['avg_sentence_length']) - (84.6 * features['avg_word_length'])\n    \n    return features\n\n# Process all rows in dataframe\nall_features = []\nfor idx, row in tqdm(df.iterrows()):\n    text = row['cleaned_transcript']\n    has_speech = row['has_speech']\n    features = extract_enhanced_features(text, has_speech)\n    all_features.append(features)\n\n# Convert to DataFrame and add to main DataFrame\nfeatures_df = pd.DataFrame(all_features)\nenhanced_df = pd.concat([df, features_df], axis=1)\n\n# Save enhanced features\nenhanced_df.to_csv('/kaggle/working/train_features_enhanced.csv', index=False)\nprint(\"✅ Enhanced features saved to: /kaggle/working/train_features_enhanced.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T21:01:27.530143Z","iopub.execute_input":"2025-04-21T21:01:27.530752Z","iopub.status.idle":"2025-04-21T21:07:37.894803Z","shell.execute_reply.started":"2025-04-21T21:01:27.530724Z","shell.execute_reply":"2025-04-21T21:07:37.894033Z"}},"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]Device set to use cuda:0\n116it [01:32,  1.18it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n444it [06:08,  1.21it/s]","output_type":"stream"},{"name":"stdout","text":"✅ Enhanced features saved to: /kaggle/working/train_features_enhanced.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"!pip install happytransformer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T20:38:16.190592Z","iopub.execute_input":"2025-04-21T20:38:16.191364Z","iopub.status.idle":"2025-04-21T20:38:19.595394Z","shell.execute_reply.started":"2025-04-21T20:38:16.191339Z","shell.execute_reply":"2025-04-21T20:38:19.594368Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: happytransformer in /usr/local/lib/python3.11/dist-packages (3.0.0)\nRequirement already satisfied: torch>=1.0 in /usr/local/lib/python3.11/dist-packages (from happytransformer) (2.5.1+cu124)\nRequirement already satisfied: tqdm>=4.43 in /usr/local/lib/python3.11/dist-packages (from happytransformer) (4.67.1)\nRequirement already satisfied: transformers<5.0.0,>=4.30.1 in /usr/local/lib/python3.11/dist-packages (from happytransformer) (4.51.1)\nRequirement already satisfied: datasets<3.0.0,>=2.13.1 in /usr/local/lib/python3.11/dist-packages (from happytransformer) (2.21.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from happytransformer) (0.2.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from happytransformer) (3.20.3)\nRequirement already satisfied: accelerate<1.0.0,>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from happytransformer) (0.34.2)\nRequirement already satisfied: tokenizers<1.0.0,>=0.13.3 in /usr/local/lib/python3.11/dist-packages (from happytransformer) (0.21.0)\nRequirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from happytransformer) (0.19.6)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (6.0.2)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (0.30.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (0.5.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<3.0.0,>=2.13.1->happytransformer) (2024.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (3.11.16)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0->happytransformer) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0->happytransformer) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.30.1->happytransformer) (2024.11.6)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (4.3.7)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (2.11.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (2.21.0)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->happytransformer) (75.1.0)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb->happytransformer) (1.17.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (1.19.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->happytransformer) (4.0.12)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->happytransformer) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->happytransformer) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->happytransformer) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.13.1->happytransformer) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.13.1->happytransformer) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.13.1->happytransformer) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.13.1->happytransformer) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0->happytransformer) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<3.0.0,>=2.13.1->happytransformer) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<3.0.0,>=2.13.1->happytransformer) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<3.0.0,>=2.13.1->happytransformer) (2025.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->happytransformer) (5.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2024.2.0)\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Ridge\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# Define features\nfeatures = [\n    'has_speech',  # Include speech flag\n    'grammar_errors', \n    'avg_sentence_length', \n    'pos_diversity',\n    'word_count', \n    'grammar_errors_per_word',\n    'gec_edits', \n    'gec_edit_rate',\n    'lexical_diversity',\n    'avg_word_length',\n    'readability_score'\n]\n\nX = enhanced_df[features]\ny = enhanced_df['label']\n\n# Split data for training\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Feature-based models\nmodel_rf = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel_lgb = lgb.LGBMRegressor(n_estimators=100, random_state=42)\nmodel_ridge = Ridge(alpha=1.0)\n\n# Train models\nmodel_rf.fit(X_train, y_train)\nmodel_lgb.fit(X_train, y_train)\nmodel_ridge.fit(X_train, y_train)\n\n# Predict on validation\npred_rf = model_rf.predict(X_val)\npred_lgb = model_lgb.predict(X_val)\npred_ridge = model_ridge.predict(X_val)\n\n# Ensemble (averaged predictions)\nensemble_feat_preds = (pred_rf + pred_lgb + pred_ridge) / 3\n\n# Evaluation\nmae = mean_absolute_error(y_val, ensemble_feat_preds)\nrmse = np.sqrt(mean_squared_error(y_val, ensemble_feat_preds))\ncorr, _ = pearsonr(y_val, ensemble_feat_preds)\n\nprint(f\"📊 Feature Ensemble MAE: {mae:.3f}\")\nprint(f\"📉 Feature Ensemble RMSE: {rmse:.3f}\")\nprint(f\"🔗 Feature Ensemble Pearson Correlation: {corr:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T21:07:43.135353Z","iopub.execute_input":"2025-04-21T21:07:43.135641Z","iopub.status.idle":"2025-04-21T21:07:43.411546Z","shell.execute_reply.started":"2025-04-21T21:07:43.135621Z","shell.execute_reply":"2025-04-21T21:07:43.410713Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000077 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 900\n[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 10\n[LightGBM] [Info] Start training from score 4.001408\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n📊 Feature Ensemble MAE: 0.820\n📉 Feature Ensemble RMSE: 1.016\n🔗 Feature Ensemble Pearson Correlation: 0.516\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom datasets import Dataset\nimport torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport os\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n# Prepare text data for transformer model\ntext_df = enhanced_df[['cleaned_transcript', 'label', 'has_speech']]\ntext_df = text_df.rename(columns={'cleaned_transcript': 'text'})\n\n# Split for transformer model\ntrain_text, val_text = train_test_split(text_df, test_size=0.2, random_state=42)\n\n# Create HuggingFace datasets\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\ntrain_hf = Dataset.from_pandas(train_text[['text', 'label']])\nval_hf = Dataset.from_pandas(val_text[['text', 'label']])\ntrain_hf = train_hf.map(tokenize)\nval_hf = val_hf.map(tokenize)\ntrain_hf = train_hf.rename_column(\"label\", \"labels\")\nval_hf = val_hf.rename_column(\"label\", \"labels\")\n\n# DistilBERT for regression\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert-base-uncased\", num_labels=1\n)\n\n# Metrics calculation\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    preds = predictions.squeeze()\n    mse = ((preds - labels) ** 2).mean()\n    mae = np.abs(preds - labels).mean()\n    corr = np.corrcoef(preds, labels)[0, 1]\n    return {\"mae\": mae, \"mse\": mse, \"pearson\": corr}\n\n# Training arguments for version 4.51.1\n# Training arguments for version 4.51.1\nargs = TrainingArguments(\n    output_dir=\"./bert-regressor\",\n    eval_steps=25,\n    logging_steps=25,\n    save_steps=0,  # equivalent to save_strategy=\"no\"\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=8,\n    num_train_epochs=12,\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    disable_tqdm=False,\n    report_to=\"none\",  # Using string \"none\" instead of None\n    dataloader_pin_memory=False,\n)\n\n# Set device\nif torch.cuda.is_available():\n    model.to(\"cuda\")\n    print(\"✅ Model on GPU\")\n\n# Create trainer and train\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_hf,\n    eval_dataset=val_hf,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\n\n# Get transformer predictions on validation set\nbert_preds_val = trainer.predict(val_hf).predictions.squeeze()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T21:07:55.308164Z","iopub.execute_input":"2025-04-21T21:07:55.308673Z","iopub.status.idle":"2025-04-21T21:08:49.048570Z","shell.execute_reply.started":"2025-04-21T21:07:55.308650Z","shell.execute_reply":"2025-04-21T21:08:49.047786Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/355 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7297b8014544451893115a5c19230097"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/89 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc4e4c7bfc524c2cb114edcfbed8fd35"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"✅ Model on GPU\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1068' max='1068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1068/1068 00:51, Epoch 12/12]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>8.529200</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.694800</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.915200</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.181200</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>1.052100</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.956600</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>0.892900</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.829800</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>0.776000</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.482800</td>\n    </tr>\n    <tr>\n      <td>275</td>\n      <td>0.714800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.436400</td>\n    </tr>\n    <tr>\n      <td>325</td>\n      <td>0.369300</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.448400</td>\n    </tr>\n    <tr>\n      <td>375</td>\n      <td>0.338000</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.640300</td>\n    </tr>\n    <tr>\n      <td>425</td>\n      <td>0.290400</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.203500</td>\n    </tr>\n    <tr>\n      <td>475</td>\n      <td>0.237500</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.311400</td>\n    </tr>\n    <tr>\n      <td>525</td>\n      <td>0.186100</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.216400</td>\n    </tr>\n    <tr>\n      <td>575</td>\n      <td>0.205800</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.145900</td>\n    </tr>\n    <tr>\n      <td>625</td>\n      <td>0.275100</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.203900</td>\n    </tr>\n    <tr>\n      <td>675</td>\n      <td>0.167100</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.102000</td>\n    </tr>\n    <tr>\n      <td>725</td>\n      <td>0.136400</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.099900</td>\n    </tr>\n    <tr>\n      <td>775</td>\n      <td>0.236700</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.081100</td>\n    </tr>\n    <tr>\n      <td>825</td>\n      <td>0.123300</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.096400</td>\n    </tr>\n    <tr>\n      <td>875</td>\n      <td>0.193800</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.123900</td>\n    </tr>\n    <tr>\n      <td>925</td>\n      <td>0.219100</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.066300</td>\n    </tr>\n    <tr>\n      <td>975</td>\n      <td>0.066200</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.114900</td>\n    </tr>\n    <tr>\n      <td>1025</td>\n      <td>0.095000</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.167100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":75},{"cell_type":"code","source":"# ======== META ENSEMBLE ========\n\nfrom sklearn.linear_model import LinearRegression\n\n# Stack predictions from both model types\nstacked_val = np.vstack([bert_preds_val, ensemble_feat_preds]).T\n\n# Train meta-regressor\nmeta_model = LinearRegression()\nmeta_model.fit(stacked_val, y_val)\n\n# Final predictions with meta-ensemble\nfinal_val_preds = meta_model.predict(stacked_val)\n\n# Handle non-speech cases specially\nfor i, has_speech in enumerate(val_text['has_speech'].values):\n    if not has_speech:\n        # Calculate default score for non-speech from training\n        nonspeech_default = enhanced_df[~enhanced_df['has_speech']]['label'].median() if sum(~enhanced_df['has_speech']) > 0 else 3\n        final_val_preds[i] = nonspeech_default\n\n# Final evaluation\nmae = mean_absolute_error(y_val, final_val_preds)\nrmse = np.sqrt(mean_squared_error(y_val, final_val_preds))\npearson = pearsonr(y_val, final_val_preds)[0]\n\nprint(f\"📊 Final Meta-Ensemble MAE: {mae:.3f}\")\nprint(f\"📉 Final Meta-Ensemble RMSE: {rmse:.3f}\")\nprint(f\"🔗 Final Meta-Ensemble Pearson: {pearson:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T21:08:52.715572Z","iopub.execute_input":"2025-04-21T21:08:52.715861Z","iopub.status.idle":"2025-04-21T21:08:52.729136Z","shell.execute_reply.started":"2025-04-21T21:08:52.715838Z","shell.execute_reply":"2025-04-21T21:08:52.728443Z"}},"outputs":[{"name":"stdout","text":"📊 Final Meta-Ensemble MAE: 0.599\n📉 Final Meta-Ensemble RMSE: 0.769\n🔗 Final Meta-Ensemble Pearson: 0.751\n","output_type":"stream"}],"execution_count":76},{"cell_type":"code","source":"# Define test paths\nTEST_AUDIO_DIR = '/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test'\nTEST_CSV_PATH = '/kaggle/input/shl-intern-hiring-assessment/Dataset/test.csv'\nTEST_PROCESSED_DIR = '/kaggle/working/processed_test_audio'\nos.makedirs(TEST_PROCESSED_DIR, exist_ok=True)\n\n# Load test data\ntest_df = pd.read_csv(TEST_CSV_PATH)\n\n# Process test audio\nspeech_flags_test = []\nfor filename in tqdm(test_df['filename']):\n    in_path = os.path.join(TEST_AUDIO_DIR, filename)\n    out_path = os.path.join(TEST_PROCESSED_DIR, filename)\n    \n    preprocess_audio(in_path, out_path)\n    has_speech = detect_speech_content(out_path)\n    speech_flags_test.append(has_speech)\n\ntest_df['has_speech'] = speech_flags_test\n\n# Transcribe test audio\ntranscripts_test = []\nfor idx, row in tqdm(test_df.iterrows()):\n    fname = row['filename']\n    audio_path = os.path.join(TEST_PROCESSED_DIR, fname)\n    \n    if row['has_speech']:\n        result = whisper_model.transcribe(audio_path, language='en')\n        transcript = result['text']\n    else:\n        transcript = \"\"\n        \n    transcripts_test.append(transcript)\n\ntest_df['transcript'] = transcripts_test\n\n# Clean test transcripts\ntest_df['cleaned_transcript'] = test_df['transcript'].apply(clean_transcript)\n\n# Save cleaned test data\ntest_df.to_csv('/kaggle/working/test_cleaned.csv', index=False)\nprint(\"✅ Cleaned test transcripts saved.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T21:08:55.992651Z","iopub.execute_input":"2025-04-21T21:08:55.993559Z","iopub.status.idle":"2025-04-21T21:20:51.481736Z","shell.execute_reply.started":"2025-04-21T21:08:55.993532Z","shell.execute_reply":"2025-04-21T21:20:51.480981Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 204/204 [02:55<00:00,  1.16it/s]\n204it [08:59,  2.65s/it]","output_type":"stream"},{"name":"stdout","text":"✅ Cleaned test transcripts saved.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"# Extract features for test set\ntest_features = []\nfor idx, row in tqdm(test_df.iterrows()):\n    text = row['cleaned_transcript']\n    has_speech = row['has_speech']\n    features = extract_enhanced_features(text, has_speech)\n    test_features.append(features)\n# Convert to DataFrame and merge with test data\ntest_features_df = pd.DataFrame(test_features)\ntest_enhanced_df = pd.concat([test_df, test_features_df], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T21:20:58.023705Z","iopub.execute_input":"2025-04-21T21:20:58.024381Z","iopub.status.idle":"2025-04-21T21:23:45.872410Z","shell.execute_reply.started":"2025-04-21T21:20:58.024356Z","shell.execute_reply":"2025-04-21T21:23:45.871723Z"}},"outputs":[{"name":"stderr","text":"204it [02:47,  1.22it/s]\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"# ======== PREDICT ON TEST SET ========\n\n# Prepare test data for transformer model\ntest_hf = Dataset.from_pandas(test_df[['cleaned_transcript']].rename(columns={\"cleaned_transcript\": \"text\"}))\ntest_hf = test_hf.map(tokenize)\n\n# Get transformer predictions\nbert_test_preds = trainer.predict(test_hf).predictions.squeeze()\n\n# Get feature-based predictions\n# Match training features exactly\ntraining_feature_cols = model_rf.feature_names_in_  # Automatically stores features seen at .fit()\nX_test_feat = test_enhanced_df[training_feature_cols]\n\n\npred_rf_test = model_rf.predict(X_test_feat)\npred_lgb_test = model_lgb.predict(X_test_feat)\npred_ridge_test = model_ridge.predict(X_test_feat)\nensemble_feat_test_preds = (pred_rf_test + pred_lgb_test + pred_ridge_test) / 3\n\n# Stack and apply meta-regressor\nstacked_test_preds = np.vstack([bert_test_preds, ensemble_feat_test_preds]).T\nfinal_test_preds = meta_model.predict(stacked_test_preds)\n\n# Special handling for non-speech files\nnonspeech_default = enhanced_df[~enhanced_df['has_speech']]['label'].median() if sum(~enhanced_df['has_speech']) > 0 else 3\nfor i, has_speech in enumerate(test_df['has_speech']):\n    if not has_speech:\n        final_test_preds[i] = nonspeech_default\n\n# Round and clip predictions to valid range [0-5]\ntest_df['label'] = np.round(final_test_preds).astype(int).clip(0, 5)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T21:30:42.559605Z","iopub.execute_input":"2025-04-21T21:30:42.559922Z","iopub.status.idle":"2025-04-21T21:30:43.258637Z","shell.execute_reply.started":"2025-04-21T21:30:42.559902Z","shell.execute_reply":"2025-04-21T21:30:43.257899Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/204 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"978e8b83897e4502ba80d6e174e3023e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"# ======== GENERATE SUBMISSION ========\n\nsubmission = test_df[['filename', 'label']]\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T21:30:51.005865Z","iopub.execute_input":"2025-04-21T21:30:51.006485Z","iopub.status.idle":"2025-04-21T21:30:51.012603Z","shell.execute_reply.started":"2025-04-21T21:30:51.006454Z","shell.execute_reply":"2025-04-21T21:30:51.011901Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}